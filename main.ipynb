{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write implementation on PyTorch for TransE model (you can use TorchGeometric or DGL library for working with graphs) and train your model on WordNet18RR dataset (you can use loaded dataset from any graph library).\n",
    "\n",
    "As a result, you must provide a link to github (or gitlab) with all the source code.\n",
    "The readability of the code, the presence of comments, type annotations, and the quality of the code as a whole will be taken into account when checking the test case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Callable, Optional\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import WordNet18RR\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_norm = lambda x, y: torch.linalg.norm((x-y), ord=1)\n",
    "l2_norm = lambda x, y: torch.linalg.norm((x-y), ord=2)\n",
    "\n",
    "def normalize(x: Union[torch.Tensor, np.ndarray], axis: int=1):\n",
    "    \"\"\" Normalize the matrix x along the specified axis\n",
    "\n",
    "    Args:\n",
    "        x (Union[torch.Tensor, np.ndarray]): _description_\n",
    "        axis (int, optional): 0 = columns, 1 = rows. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        (Union[torch.Tensor, np.ndarray]): returns a matrix with the same dtype as the input\n",
    "    \"\"\"\n",
    "    return_tensor = False\n",
    "\n",
    "    if x.dtype == torch.Tensor:\n",
    "        x = x.numpy()\n",
    "        return_tensor = True\n",
    "    \n",
    "    x = np.apply_along_axis(func1d=lambda x: x / np.linalg.norm(x), arr=x, axis=axis)\n",
    "\n",
    "    if return_tensor:\n",
    "        return torch.from_numpy(x)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetDataset(Dataset):\n",
    "    def __init__(self, path=\"WordNet18RR/raw/\") -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index) -> int:\n",
    "        return super().__getitem__(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-2930c4c5bd34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0medge_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "class Edge():\n",
    "    def __init__(self, u, v, label) -> None:\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.label = label\n",
    "\n",
    "with open(\"WordNet18RR/raw/train.txt\") as f:\n",
    "    tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "\n",
    "next(tsv_reader)\n",
    "\n",
    "edge_list = list()\n",
    "\n",
    "for row in tsv_reader:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(pl.LightningModule):\n",
    "    def __init__(self, n_entities: int, n_relations: int, margin: int=1, emb_dim: int=50,\n",
    "                 distance_func: Callable[[torch.Tensor, torch.Tensor], torch.Tensor]=l1_norm) -> None:\n",
    "        \"\"\" Instatiate the entity and relation matrix of the TransE model\n",
    "            https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "\n",
    "        Args:\n",
    "            n_entities (int): _description_\n",
    "            n_relations (int): _description_\n",
    "            margin (int, optional): _description_. Defaults to 1.\n",
    "            emb_dim (int, optional): _description_. Defaults to 50.\n",
    "            distance_func (Callable[[torch.Tensor, torch.Tensor], torch.Tensor], optional): _description_. Defaults to l1_norm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.emb_dim = emb_dim\n",
    "        self.distance_func = distance_func\n",
    "\n",
    "        val = 6/np.sqrt(emb_dim)\n",
    "        entity_size = (n_entities, emb_dim)\n",
    "        relation_size = (n_relations, emb_dim)\n",
    "\n",
    "        # instantiate matrices\n",
    "        entity_mat = np.random.uniform(low=-val, high=val, size=entity_size)\n",
    "        relation_mat = np.random.uniform(low=val, high=val, size=relation_size)\n",
    "\n",
    "        # normalize matrices\n",
    "        entity_mat = normalize(entity_mat)\n",
    "        relation_mat = normalize(relation_mat)\n",
    "\n",
    "        # cast to torch\n",
    "        self.entity_mat = torch.from_numpy(entity_mat)\n",
    "        self.relation_mat = torch.from_numpy(relation_mat)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\" batch is the list of ids of edge within the batch \"\"\"\n",
    "        return self.relation_mat \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WordNet18RR('./WordNet18RR/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'link_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-f525c34bddb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./WordNet18RR/processed/data.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinkLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'link_sampler'"
     ]
    }
   ],
   "source": [
    "data = torch.load(\"./WordNet18RR/processed/data.pt\")[0]\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE(n_entities=data.num_nodes,\n",
    "               n_relations=data.num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms.random_link_split import RandomLinkSplit\n",
    "\n",
    "rls = RandomLinkSplit()\n",
    "train_data, val_data, test_data = rls(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_loader = DataLoader(range(train_data.edge_index.shape[1]), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 93003], edge_type=[93003], train_mask=[93003], val_mask=[93003], test_mask=[93003], num_nodes=40943)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str=\"WordNet18RR/raw\", batch_size: int=32) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage: Optional[str]=None):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
