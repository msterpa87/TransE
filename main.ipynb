{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write implementation on PyTorch for TransE model (you can use TorchGeometric or DGL library for working with graphs) and train your model on WordNet18RR dataset (you can use loaded dataset from any graph library).\n",
    "\n",
    "As a result, you must provide a link to github (or gitlab) with all the source code.\n",
    "The readability of the code, the presence of comments, type annotations, and the quality of the code as a whole will be taken into account when checking the test case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Union, Callable, Optional, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.datasets import WordNet18RR, WordNet18\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# needed \n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# check if CUDA device is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both versions of the WordNet18 dataset have been imported through the PyTorch Geometric library. We highlight that training/testing on the original WN18 was done solely to compare the implemented model best performance against the results from **Borders et al.** (table 3 page 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordNet18RR()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download wordnet dataset\n",
    "WordNet18('./WordNet18/')\n",
    "WordNet18RR('./WordNet18RR/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset and DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a custom dataset that reads from the raw directory of the WordNet18 downloaded in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge():\n",
    "    def __init__(self, head, tail, rel) -> None:\n",
    "        self.head = head\n",
    "        self.tail = tail\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.head} {self.rel} {self.tail}\"\n",
    "\n",
    "def process_lines(lines: List[str], delim: str='\\t'):\n",
    "    \"\"\" cleans up the input set of strings \"\"\"\n",
    "    return list(map(lambda s: s.strip('\\n').split(delim), lines))\n",
    "\n",
    "def load_edges_from_file(path: str, is_wn18: bool=True):\n",
    "    \"\"\" read edges from the text file in raw, considering the different\n",
    "        formats of RR (head, rel, tail) and original version (head, tail, rel) \"\"\"\n",
    "    edge_list = list()\n",
    "\n",
    "    lines = open(path).readlines()\n",
    "\n",
    "    # WN18 contains a header line and has a format (head, tail, rel)\n",
    "    if is_wn18:\n",
    "        lines = lines[1:]\n",
    "        delim = ' '\n",
    "    else:\n",
    "        delim = '\\t'\n",
    "\n",
    "    lines = process_lines(lines, delim=delim)\n",
    "\n",
    "    # the two WN version have a different format to represent edges/relation\n",
    "    if is_wn18:\n",
    "        edge_list = [Edge(head=head, tail=tail, rel=rel) for head, tail, rel in lines]\n",
    "    else:\n",
    "        edge_list = [Edge(head=head, tail=tail, rel=rel) for head, rel, tail in lines]\n",
    "    \n",
    "    return edge_list\n",
    "\n",
    "def load_ids_dict(path: str) -> Union[dict, dict]:\n",
    "    \"\"\" reads and return the dictionaries entity->id and relation->id \n",
    "        from the specified location \"\"\"\n",
    "    \n",
    "    assert(os.path.exists(path))\n",
    "\n",
    "    entity2id = process_lines(open(os.path.join(path, \"entity2id.txt\")))\n",
    "    relation2id = process_lines(open(os.path.join(path, \"relation2id.txt\")))\n",
    "\n",
    "    entity2id = dict([(x[0], int(x[1])) for x in entity2id])\n",
    "    relation2id = dict([(x[0], int(x[1])) for x in relation2id])\n",
    "\n",
    "    return entity2id, relation2id\n",
    "\n",
    "def create_id_mappings(dataset_str: str=\"WordNet18RR\") -> None:\n",
    "    \"\"\" creates the mapping ids inside the raw directory of the \n",
    "        specified version of WordNet18 \"\"\"\n",
    "\n",
    "    assert(dataset_str in [\"WordNet18\", \"WordNet18RR\"])\n",
    "\n",
    "    is_wn18 = dataset_str == \"WordNet18\"\n",
    "    path = f\"./{dataset_str}/raw/\"\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory {path} does not exist\")\n",
    "        return\n",
    "    \n",
    "    # read edge_list from the raw text files\n",
    "    train_edge_list = load_edges_from_file(os.path.join(path, \"train.txt\"), is_wn18=is_wn18)\n",
    "    val_edge_list = load_edges_from_file(os.path.join(path, \"valid.txt\"), is_wn18=is_wn18)\n",
    "    test_edge_list = load_edges_from_file(os.path.join(path, \"test.txt\"), is_wn18=is_wn18)\n",
    "\n",
    "    entity_list = list()\n",
    "    relation_list = list()\n",
    "\n",
    "    # assign unique id to each entity/relation\n",
    "    for edge_list in [train_edge_list, val_edge_list, test_edge_list]:\n",
    "        entity_list += [x.head for x in edge_list] + [x.tail for x in edge_list]\n",
    "        relation_list += [x.rel for x in edge_list]\n",
    "\n",
    "    entity_list = sorted(list(set(entity_list)))\n",
    "    entity2id = dict(zip(entity_list, range(len(entity_list))))\n",
    "\n",
    "    relation_list = sorted(list(set(relation_list)))\n",
    "    relation2id = dict(zip(relation_list, range(len(relation_list))))\n",
    "\n",
    "    # save the generated mappings into the raw directory\n",
    "    with open(os.path.join(path, \"entity2id.txt\"), \"w\") as f:\n",
    "        f.writelines([f\"{x}\\t{y}\\n\" for x,y in entity2id.items()])\n",
    "\n",
    "    with open(os.path.join(path, \"relation2id.txt\"), \"w\") as f:\n",
    "        f.writelines([f\"{x}\\t{y}\\n\" for x,y in relation2id.items()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate the mappings we simply call the *create_id_mappings()* function specifying the WN version we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_id_mappings(\"WordNet18RR\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a PyTorch dataset and a Data Module that can be handled by PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetDataset(Dataset):\n",
    "    def __init__(self, dataset: str=\"WordNet18RR\", split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        self.path = f\"./{dataset}/raw\"\n",
    "\n",
    "        if split == 'val':\n",
    "            split = 'valid'\n",
    "        self.split = split\n",
    "\n",
    "        is_wn18 = dataset == \"WordNet18\"\n",
    "\n",
    "        edge_list = load_edges_from_file(os.path.join(self.path, f\"{self.split}.txt\"), is_wn18=is_wn18)\n",
    "        entity2id, relation2id = load_ids_dict(path=self.path)\n",
    "\n",
    "        self.edge_list = torch.tensor([(entity2id[e.head], entity2id[e.tail]) for e in edge_list])\n",
    "        self.relation_list = torch.tensor([relation2id[e.rel] for e in edge_list])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.edge_list.shape[0]\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int,int]:\n",
    "        return self.edge_list[index], self.relation_list[index]\n",
    "\n",
    "class WordNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset: str=\"WordNet18RR\", batch_size=32) -> None:\n",
    "        super().__init__()\n",
    "        self.path = f\"./{dataset}/raw\"\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_entities = 40943\n",
    "\n",
    "        if dataset == 'WordNet18RR':\n",
    "            self.num_relations = 11\n",
    "        else:\n",
    "            self.num_relations = 18\n",
    "        \n",
    "        self.params = {\"pin_memory\": True, \"batch_size\": batch_size}\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = WordNetDataset(dataset=self.dataset, split=\"train\")\n",
    "            self.val_dataset = WordNetDataset(dataset=self.dataset, split=\"valid\")\n",
    "        \n",
    "        if stage == \"predict\":\n",
    "            self.test_dataset = WordNetDataset(dataset=self.dataset, split=\"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, shuffle=True, **self.params)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, shuffle=False, **self.params)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, shuffle=False, **self.params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(pl.LightningModule):\n",
    "    def __init__(self, margin: int=1, emb_dim: int=20, learning_rate=0.01, p_norm=1, dataset=\"WordNet18RR\") -> None:\n",
    "        \"\"\" Instatiate the entity and relation matrix of the TransE model\n",
    "            https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "\n",
    "        Args:\n",
    "            n_entities (int): _description_\n",
    "            n_relations (int): _description_\n",
    "            margin (int, optional): _description_. Defaults to 1.\n",
    "            emb_dim (int, optional): _description_. Defaults to 50.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.emb_dim = emb_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.p_norm = p_norm\n",
    "\n",
    "        # dataset specific values\n",
    "        self.num_entities = 40943\n",
    "\n",
    "        if dataset == \"WordNet18\":\n",
    "            self.num_relations = 18\n",
    "        else:\n",
    "            self.num_relations = 11\n",
    "\n",
    "        # initialize embeddings\n",
    "        self.entity_mat = nn.Embedding(self.num_entities, emb_dim).to(self.device)\n",
    "        self.relation_mat = nn.Embedding(self.num_relations, emb_dim).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # initialize with random uniform\n",
    "            val = 6/np.sqrt(emb_dim)\n",
    "            self.entity_mat.weight.uniform_(-val, val)\n",
    "            self.relation_mat.weight.uniform_(-val, val)\n",
    "\n",
    "            # normalize entity and relation embeddings\n",
    "            self.entity_mat.weight.copy_(F.normalize(self.entity_mat.weight, p=self.p_norm, dim=-1))\n",
    "            self.relation_mat.weight.copy_(F.normalize(self.relation_mat.weight, p=self.p_norm, dim=-1))\n",
    "\n",
    "    def corrupt_edge_list_OLDVERSION(self, edge_list: torch.Tensor) -> Union[torch.tensor, torch.tensor]:\n",
    "        \"\"\" given a list of edges return two lists of edges where either head \n",
    "            or tail has been randomly replaced by any other entity \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        # sample random entity replacements\n",
    "        r1 = np.random.choice(entity_list, size=n)\n",
    "        r2 = np.random.choice(entity_list, size=n)\n",
    "\n",
    "        corrupted_heads = edge_list.detach().clone()\n",
    "        corrupted_tails = edge_list.detach().clone()\n",
    "\n",
    "        corrupted_heads[:,0] = torch.from_numpy(r1)\n",
    "        corrupted_tails[:,1] = torch.from_numpy(r2)\n",
    "                \n",
    "        return corrupted_heads, corrupted_tails\n",
    "\n",
    "    def corrupt_edge_list(self, edge_list: torch.Tensor) -> Union[torch.tensor, torch.tensor]:\n",
    "        \"\"\" given a list of edges return two lists of edges where either head \n",
    "            or tail has been randomly replaced by any other entity \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        heads = edge_list[:,0]\n",
    "        tails = edge_list[:, 1]\n",
    "\n",
    "        # sample random entity replacements\n",
    "        sample = np.random.choice(entity_list, size=n)\n",
    "        sample = torch.from_numpy(sample).type(torch.int64).to(self.device)\n",
    "\n",
    "        # random selection of either head or tail\n",
    "        pos = np.random.choice([0, 1], size=n)\n",
    "        pos = torch.from_numpy(pos).type(torch.int64).to(self.device)\n",
    "        pos = pos.reshape(-1,1)\n",
    "\n",
    "        corrupted_heads = torch.vstack([heads, sample]).T\n",
    "        corrupted_heads = corrupted_heads.gather(1, pos.reshape(-1,1))\n",
    "\n",
    "        corrupted_tails = torch.vstack([tails, sample]).T\n",
    "        corrupted_tails = corrupted_tails.gather(1, (1-pos).reshape(-1,1))\n",
    "\n",
    "        corrupted_triplet = torch.hstack([corrupted_heads, corrupted_tails])\n",
    "        corrupted_triplet\n",
    "        \n",
    "        return corrupted_triplet\n",
    "\n",
    "    \n",
    "    def embedding_loss(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        \n",
    "        loss = torch.zeros(1).to(self.device)\n",
    "\n",
    "        corrupted_triplet = self.corrupt_edge_list(edge_list)\n",
    "        #corrupted_heads, corrupted_tails = self.corrupt_edge_list(edge_list)\n",
    "        \n",
    "        # take embedding values for entities and relations\n",
    "        \"\"\" t1 = self.entity_mat.weight[edge_list.repeat(2,1)]\n",
    "        t2 = torch.vstack([self.entity_mat.weight[corrupted_heads],\n",
    "                           self.entity_mat.weight[corrupted_tails]])\n",
    "        rel = self.relation_mat.weight[labels].repeat(2,1) \"\"\"\n",
    "\n",
    "        t1 = self.entity_mat.weight[edge_list]\n",
    "        t2 = self.entity_mat.weight[corrupted_triplet]\n",
    "        rel = self.relation_mat.weight[labels]\n",
    "\n",
    "        # normalize entity (maybe unnecessary here)\n",
    "        t1 = F.normalize(t1, p=self.p_norm, dim=-1)\n",
    "        t2 = F.normalize(t2, p=self.p_norm, dim=-1)\n",
    "\n",
    "        # compute the loss value\n",
    "        pos = torch.norm(t1[:,0,:] + rel - t1[:,1,:], dim=-1, p=self.p_norm)\n",
    "        neg = torch.norm(t2[:,0,:] + rel - t2[:,1,:], dim=-1, p=self.p_norm)\n",
    "        loss = torch.clip((self.margin + pos - neg), min=0).sum()\n",
    "        \n",
    "        \"\"\" target = torch.ones(pos.shape[0]).to(self.device)\n",
    "        torch.set_grad_enabled(True)\n",
    "        F.margin_ranking_loss(input1=pos, input2=neg, target=target, margin=self.margin) \"\"\"\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluation_protocol(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        batch_size = edge_list.shape[0]\n",
    "\n",
    "        # combine heads, tails and labels\n",
    "        triplets = torch.hstack([edge_list, labels.reshape(-1,1)])\n",
    "\n",
    "        # repeat all triplets for n_entities times\n",
    "        triplets = triplets[:,np.newaxis,:].repeat(1,self.num_entities,1)\n",
    "\n",
    "        true_pos_total = list()\n",
    "        rank_pos_list = list()\n",
    "\n",
    "        # repeat corruption for both head and tail\n",
    "        for pos in [0,1]:\n",
    "            x = triplets.detach().clone()\n",
    "            \n",
    "            # replace all heads/tails with list of all possible entities\n",
    "            x[:,:,pos] = torch.tensor(range(self.num_entities))[np.newaxis,:].repeat(batch_size,1).to(self.device)\n",
    "\n",
    "            # triplets are arranged as (head, tail, label)\n",
    "            head = self.entity_mat.weight[x[:,:,0]]\n",
    "            tail = self.entity_mat.weight[x[:,:,1]]\n",
    "            rel = self.relation_mat.weight[x[:,:,2]]\n",
    "\n",
    "            # compute distance between head + label and tail\n",
    "            norms = torch.norm(head + rel - tail, dim=-1, p=self.p_norm)\n",
    "\n",
    "            # get index positions of sorted norms for each triplet\n",
    "            rankings = torch.vstack([torch.argsort(x) for x in norms.unbind(dim=0)])\n",
    "\n",
    "            # find position of heads within the rankings\n",
    "            torch.save(rankings, \"rankings.pt\")\n",
    "            torch.save(edge_list, \"edge_list.pt\")\n",
    "            rank_pos = torch.where(rankings == edge_list[:,pos].reshape(-1,1))[1]\n",
    "\n",
    "            rank_pos_list.append(rank_pos)\n",
    "            true_pos_total.append(rank_pos < 10)\n",
    "\n",
    "        return torch.vstack(rank_pos_list).flatten()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.embedding_loss(batch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.embedding_loss(batch)\n",
    "        batch_rankings = self.evaluation_protocol(batch)\n",
    "        self.log_dict({\"val_loss\": loss}, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"batch_rankings\": batch_rankings}\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        batch_rankings = self.evaluation_protocol(batch)\n",
    "        return {\"batch_rankings\": batch_rankings}\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        with torch.no_grad():\n",
    "             # keep entities embeddings normalized\n",
    "            self.entity_mat.weight.copy_(F.normalize(self.entity_mat.weight, p=2, dim=1))\n",
    "    \n",
    "    def compute_epoch_metrics(self, outputs, stage, log_value=True):\n",
    "        epoch_rankings = torch.hstack([x['batch_rankings'] for x in outputs])\n",
    "        mean_rank = epoch_rankings.float().float().mean()\n",
    "        hit_at_10 = (epoch_rankings < 10).float().mean()*100\n",
    "        if log_value:\n",
    "            self.log_dict({f\"{stage}_mean_rank\": mean_rank,\n",
    "                           f\"{stage}_hits@10\": hit_at_10},\n",
    "                           prog_bar=True, on_epoch=True)\n",
    "        else:\n",
    "            return mean_rank, hit_at_10\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.compute_epoch_metrics(outputs, stage=\"val\")\n",
    "\n",
    "    def prediction_epoch_end(self, outputs):\n",
    "        self.compute_epoch_metrics(outputs, stage=\"predict\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transe(config,\n",
    "                 max_epochs=100,\n",
    "                 accelerator='gpu',\n",
    "                 num_best_ckpt=3,\n",
    "                 patience=10,\n",
    "                 min_delta=0.5,\n",
    "                 main_path='./',\n",
    "                 dataset='WordNet18RR'):\n",
    "    \n",
    "    model = TransE(emb_dim=config['emb_dim'],\n",
    "                learning_rate=config['lr'],\n",
    "                margin=config['margin'],\n",
    "                p_norm=config['p_norm'],\n",
    "                dataset=dataset)\n",
    "\n",
    "    dm = WordNetDataModule(batch_size=config['batch_size'], dataset=dataset)\n",
    "\n",
    "    dir_path = f\"ckpt_{dataset}/emb_dim={config['emb_dim']}-lr={config['lr']}-margin={config['margin']}-p_norm={config['p_norm']}\"\n",
    "    dir_path = os.path.join(main_path, dir_path)\n",
    "\n",
    "    print(dir_path)\n",
    "\n",
    "    # using mean predicted rank on validation set as described in section 4.2\n",
    "    early_stop_rank = EarlyStopping(monitor=\"val_mean_rank\",\n",
    "                                    min_delta=min_delta,\n",
    "                                    patience=patience,\n",
    "                                    verbose=False,\n",
    "                                    mode=\"min\")\n",
    "\n",
    "    # save best models based on mean rank on validation set\n",
    "    checkpoint_callback = ModelCheckpoint(save_top_k=num_best_ckpt,\n",
    "                                        monitor=\"val_mean_rank\",\n",
    "                                        dirpath=dir_path,\n",
    "                                        filename=\"transe-{dataset}-{epoch}-{val_mean_rank:.0f}-{val_hits@10:.1f}\")\n",
    "\n",
    "    logger = TensorBoardLogger(f'tb_logs_{dataset}', name='TransE')\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                        accelerator=accelerator,\n",
    "                        callbacks=[checkpoint_callback, early_stop_rank],\n",
    "                        logger=logger)\n",
    "\n",
    "    try:\n",
    "        # resume from best model if checkpoint is available\n",
    "        ckpt_path = os.path.join(dir_path, os.listdir(dir_path)[-1])\n",
    "    except:\n",
    "        ckpt_path = None\n",
    "\n",
    "    trainer.fit(model, datamodule=dm, ckpt_path=ckpt_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112: 100%|██████████| 1146/1146 [00:46<00:00, 24.83it/s, loss=9.71, v_num=27, val_loss=20.40, val_mean_rank=346.0, val_hits@10=53.10] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73:  40%|████      | 462/1146 [00:08<00:12, 54.20it/s, loss=189, v_num=28, val_loss=242.0, val_mean_rank=1.73e+3, val_hits@10=28.90] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# best model: emb_dim=40, lr=0.001, margin=1, p_norm=2\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": [128],\n",
    "    \"lr\": [0.001],\n",
    "    \"emb_dim\": [40],\n",
    "    \"p_norm\": [1],\n",
    "    \"margin\": [1, 2]\n",
    "}\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "import itertools\n",
    "\n",
    "keys, values = zip(*config.items())\n",
    "comb_list = [dict(zip(keys,v)) for v in itertools.product(*values)]\n",
    "\n",
    "for comb in comb_list:\n",
    "    try:\n",
    "        train_transe(config=comb, max_epochs=num_epochs, dataset=\"WordNet18\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1146/1146 [00:50<00:00, 22.85it/s, loss=165, v_num=29, val_loss=174.0, val_mean_rank=1.31e+4, val_hits@10=2.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73:  40%|████      | 462/1146 [12:56<19:09,  1.68s/it, loss=189, v_num=28, val_loss=242.0, val_mean_rank=1.73e+3, val_hits@10=28.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1146/1146 [00:49<00:00, 23.28it/s, loss=396, v_num=30, val_loss=416.0, val_mean_rank=1.69e+4, val_hits@10=1.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:49<00:00, 22.99it/s, loss=2.35e+03, v_num=31, val_loss=2.46e+3, val_mean_rank=1.66e+4, val_hits@10=1.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:38<00:00, 29.72it/s, loss=213, v_num=32, val_loss=228.0, val_mean_rank=2.05e+4, val_hits@10=0.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:40<00:00, 28.53it/s, loss=457, v_num=33, val_loss=477.0, val_mean_rank=2.19e+4, val_hits@10=0.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1146/1146 [00:48<00:00, 23.79it/s, loss=2.39e+03, v_num=34, val_loss=2.51e+3, val_mean_rank=2.11e+4, val_hits@10=0.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:52<00:00, 21.88it/s, loss=183, v_num=35, val_loss=193.0, val_mean_rank=1.5e+4, val_hits@10=1.090] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:51<00:00, 22.27it/s, loss=409, v_num=36, val_loss=432.0, val_mean_rank=1.75e+4, val_hits@10=0.280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [01:02<00:00, 18.30it/s, loss=2.35e+03, v_num=37, val_loss=2.47e+3, val_mean_rank=1.76e+4, val_hits@10=0.200]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:52<00:00, 21.64it/s, loss=217, v_num=38, val_loss=227.0, val_mean_rank=2.12e+4, val_hits@10=0.080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:41<00:00, 27.90it/s, loss=448, v_num=39, val_loss=472.0, val_mean_rank=2.22e+4, val_hits@10=0.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [01:02<00:00, 18.34it/s, loss=2.39e+03, v_num=40, val_loss=2.52e+3, val_mean_rank=2.24e+4, val_hits@10=0.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 1146/1146 [00:49<00:00, 23.21it/s, loss=44.1, v_num=41, val_loss=50.80, val_mean_rank=571.0, val_hits@10=27.00] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1146/1146 [00:49<00:00, 23.38it/s, loss=269, v_num=42, val_loss=290.0, val_mean_rank=971.0, val_hits@10=20.80]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 1146/1146 [00:48<00:00, 23.45it/s, loss=2.21e+03, v_num=43, val_loss=2.33e+3, val_mean_rank=947.0, val_hits@10=19.70]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 1146/1146 [00:48<00:00, 23.71it/s, loss=94, v_num=44, val_loss=108.0, val_mean_rank=3.93e+3, val_hits@10=6.950]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory C:\\Users\\Uni\\Desktop\\TransE\\ckpt_WordNet18\\emb_dim=20-lr=0.01-margin=2-p_norm=1 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at ./ckpt_WordNet18/emb_dim=20-lr=0.01-margin=2-p_norm=1\\transe-dataset=0-epoch=22-val_mean_rank=1439-val_hits@10=17.2.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint file at ./ckpt_WordNet18/emb_dim=20-lr=0.01-margin=2-p_norm=1\\transe-dataset=0-epoch=22-val_mean_rank=1439-val_hits@10=17.2.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 1146/1146 [00:48<00:00, 23.71it/s, loss=285, v_num=45, val_loss=313.0, val_mean_rank=1.46e+3, val_hits@10=20.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 360   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.277     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 1146/1146 [00:49<00:00, 23.37it/s, loss=2.28e+03, v_num=46, val_loss=2.41e+3, val_mean_rank=9.62e+3, val_hits@10=1.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 1146/1146 [00:57<00:00, 19.89it/s, loss=49.4, v_num=47, val_loss=56.50, val_mean_rank=590.0, val_hits@10=30.20] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 1146/1146 [00:53<00:00, 21.35it/s, loss=284, v_num=48, val_loss=302.0, val_mean_rank=1.24e+3, val_hits@10=20.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1146/1146 [00:59<00:00, 19.16it/s, loss=2.23e+03, v_num=49, val_loss=2.35e+3, val_mean_rank=1.28e+3, val_hits@10=19.30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [01:02<00:00, 18.26it/s, loss=178, v_num=50, val_loss=211.0, val_mean_rank=1.76e+4, val_hits@10=0.250]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [01:02<00:00, 18.26it/s, loss=391, v_num=51, val_loss=438.0, val_mean_rank=1.86e+4, val_hits@10=0.240]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1146/1146 [00:59<00:00, 19.27it/s, loss=2.34e+03, v_num=52, val_loss=2.48e+3, val_mean_rank=1.84e+4, val_hits@10=0.140]\n"
     ]
    }
   ],
   "source": [
    "# best model: emb_dim=40, lr=0.001, margin=1, p_norm=2\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": [128],\n",
    "    \"lr\": [0.1, 0.01],\n",
    "    \"emb_dim\": [20, 40],\n",
    "    \"p_norm\": [2, 1],\n",
    "    \"margin\": [1, 2, 10]\n",
    "}\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "import itertools\n",
    "\n",
    "keys, values = zip(*config.items())\n",
    "comb_list = [dict(zip(keys,v)) for v in itertools.product(*values)]\n",
    "\n",
    "for comb in comb_list:\n",
    "    try:\n",
    "        train_transe(config=comb, max_epochs=num_epochs, dataset=\"WordNet18\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ckpt_WordNet18/ckpt_WordNet18/emb_dim=40-lr=0.001-margin=1-p_norm=2\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 720   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.554     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  97%|█████████▋| 1117/1146 [00:38<00:00, 29.07it/s, loss=107, v_num=68]"
     ]
    }
   ],
   "source": [
    "single_train_config = {\n",
    "    'batch_size': 128,\n",
    "    'lr': 0.001,\n",
    "    'emb_dim': 40,\n",
    "    'p_norm': 2,\n",
    "    'margin': 1\n",
    "}\n",
    "\n",
    "train_transe(config=single_train_config, main_path=\"./ckpt_WordNet18/\", dataset=\"WordNet18\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at ./ckpt_WordNet18/emb_dim=40-lr=0.001-margin=1-p_norm=2/transe-dataset=0-epoch=88-val_mean_rank=202-val_hits@10=61.2.ckpt\n",
      "Loaded model weights from checkpoint at ./ckpt_WordNet18/emb_dim=40-lr=0.001-margin=1-p_norm=2/transe-dataset=0-epoch=88-val_mean_rank=202-val_hits@10=61.2.ckpt\n",
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 38\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# PREDICTION ON TEST SET\u001b[39;00m\n\u001b[0;32m     29\u001b[0m predict_config \u001b[39m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m128\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mWordNet18\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     36\u001b[0m }\n\u001b[1;32m---> 38\u001b[0m predict_transe(config\u001b[39m=\u001b[39;49mpredict_config)\n",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m, in \u001b[0;36mpredict_transe\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[39m=\u001b[39m TransE(emb_dim\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39memb_dim\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     17\u001b[0m             learning_rate\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     18\u001b[0m             margin\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmargin\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     19\u001b[0m             p_norm\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mp_norm\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m             dataset\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m pred \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(model, datamodule\u001b[39m=\u001b[39mdm, ckpt_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, filename))\n\u001b[1;32m---> 23\u001b[0m test_mean_rank, test_hits_at_10 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mcompute_epoch_metrics(pred, stage\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, log_value\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_mean_rank=\u001b[39m\u001b[39m{\u001b[39;00mtest_mean_rank\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, test_hits@10=\u001b[39m\u001b[39m{\u001b[39;00mtest_hits_at_10\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 145\u001b[0m, in \u001b[0;36mTransE.compute_epoch_metrics\u001b[1;34m(self, outputs, stage, log_value)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_epoch_metrics\u001b[39m(\u001b[39mself\u001b[39m, outputs, stage, log_value\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 145\u001b[0m     epoch_rankings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack([x[\u001b[39m'\u001b[39m\u001b[39mbatch_rankings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m outputs])\n\u001b[0;32m    146\u001b[0m     mean_rank \u001b[39m=\u001b[39m epoch_rankings\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    147\u001b[0m     hit_at_10 \u001b[39m=\u001b[39m (epoch_rankings \u001b[39m<\u001b[39m \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def hit10_from_filename(filename):\n",
    "    filename = filename.replace('.ckpt','')\n",
    "    return float(filename.split('@10=')[1])\n",
    "\n",
    "def predict_transe(config):\n",
    "    trainer = pl.Trainer()\n",
    "\n",
    "    dm = WordNetDataModule(batch_size=config['batch_size'], dataset=config['dataset'])\n",
    "\n",
    "    # ckpt_path from model config\n",
    "    path = f\"./ckpt_{config['dataset']}/emb_dim={config['emb_dim']}-lr={config['learning_rate']}-margin={config['margin']}-p_norm={config['p_norm']}/\"\n",
    "\n",
    "    # take filename of model with highest hit@10\n",
    "    filename = max(os.listdir(path), key=hit10_from_filename)\n",
    "    \n",
    "    model = TransE(emb_dim=config['emb_dim'],\n",
    "                learning_rate=config['learning_rate'],\n",
    "                margin=config['margin'],\n",
    "                p_norm=config['p_norm'],\n",
    "                dataset=config['dataset'])\n",
    "    \n",
    "    pred = trainer.predict(model, datamodule=dm, ckpt_path=os.path.join(path, filename))\n",
    "    test_mean_rank, test_hits_at_10 = model.compute_epoch_metrics(pred, stage=\"predict\", log_value=False)\n",
    "    print(\"\\n\")\n",
    "    print(f\"test_mean_rank={test_mean_rank:.0f}, test_hits@10={test_hits_at_10:.2f}%\")\n",
    "\n",
    "# PREDICTION ON TEST SET\n",
    "\n",
    "predict_config = {\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.001,\n",
    "    'emb_dim': 40,\n",
    "    'p_norm': 2,\n",
    "    'margin': 1,\n",
    "    'dataset': 'WordNet18'\n",
    "}\n",
    "\n",
    "predict_transe(config=predict_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
