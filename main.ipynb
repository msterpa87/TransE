{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write implementation on PyTorch for TransE model (you can use TorchGeometric or DGL library for working with graphs) and train your model on WordNet18RR dataset (you can use loaded dataset from any graph library).\n",
    "\n",
    "As a result, you must provide a link to github (or gitlab) with all the source code.\n",
    "The readability of the code, the presence of comments, type annotations, and the quality of the code as a whole will be taken into account when checking the test case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Callable, Optional\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import WordNet18RR\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download wordnet dataset, we'll be using the processed file data.pt\n",
    "dataset = WordNet18RR('./WordNet18RR/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Edge():\n",
    "    def __init__(self, u, v, label) -> None:\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.label = label\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.u} {self.label} {self.v}\"\n",
    "\n",
    "def load_edge_list_from_file(path: str, header: bool=False):\n",
    "    edge_list = list()\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "\n",
    "        if header:\n",
    "            next(tsv_reader)\n",
    "\n",
    "        for row in tsv_reader:\n",
    "            u, label, v = row\n",
    "            edge_list.append(Edge(u=u, v=v, label=label))\n",
    "    \n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetEdgeDataset(Dataset):\n",
    "    def __init__(self, path: str=\"WordNet18RR/processed/data.pt\", split: str=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        data = torch.load(path)[0]\n",
    "        mask_dict = {\"train\": data.train_mask, \"test\": data.test_mask, \"val\": data.val_mask}\n",
    "        mask = mask_dict[split]\n",
    "        self.edge_list = data.edge_index.T[mask, :]\n",
    "        self.edge_labels = data.edge_type[mask]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.edge_list.shape[0]\n",
    "\n",
    "    def __getitem__(self, index) -> int:\n",
    "        return self.edge_list[index,:], self.edge_labels[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str=\"WordNet18RR/processed/data.pt\", batch_size=32) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_entities = 40943\n",
    "        self.num_relations = 11\n",
    "        self.params = {\"pin_memory\": True, \"batch_size\": batch_size}\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = WordNetEdgeDataset(split=\"train\", path=self.data_dir)\n",
    "            self.val_dataset = WordNetEdgeDataset(split=\"val\", path=self.data_dir)\n",
    "        \n",
    "        if stage == \"test\":\n",
    "            self.test_dataset = WordNetEdgeDataset(split=\"test\", path=self.data_dir)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, shuffle=True, **self.params)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, shuffle=False, **self.params)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, shuffle=False, **self.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(pl.LightningModule):\n",
    "    def __init__(self, margin: int=1, emb_dim: int=50, learning_rate=0.01, p=1) -> None:\n",
    "        \"\"\" Instatiate the entity and relation matrix of the TransE model\n",
    "            https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "\n",
    "        Args:\n",
    "            n_entities (int): _description_\n",
    "            n_relations (int): _description_\n",
    "            margin (int, optional): _description_. Defaults to 1.\n",
    "            emb_dim (int, optional): _description_. Defaults to 50.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.emb_dim = emb_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.p = p\n",
    "\n",
    "        # dataset specific values\n",
    "        self.num_entities = 40943\n",
    "        self.num_relations = 11\n",
    "\n",
    "        # initialize embeddings\n",
    "        self.entity_mat = nn.Embedding(self.num_entities, emb_dim).to(self.device)\n",
    "        self.relation_mat = nn.Embedding(self.num_relations, emb_dim).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # initialize with random uniform\n",
    "            val = 6/np.sqrt(emb_dim)\n",
    "            self.entity_mat.weight.uniform_(-val, val)\n",
    "            self.relation_mat.weight.uniform_(-val, val)\n",
    "\n",
    "            # normalize entity embeddings\n",
    "            self.entity_mat.weight.copy_(nn.functional.normalize(self.entity_mat.weight, p=2, dim=1))\n",
    "\n",
    "    def corrupt_edge_list(self, edge_list: torch.Tensor):\n",
    "        \"\"\" sample either the head or tail of x from range(n) \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        idxs = (np.random.rand(edge_list.shape[0]) < 0.5).astype(int)  # pick either head or tail\n",
    "        # sample random entity replacements\n",
    "        rand_corrupted = edge_list.detach().clone()\n",
    "        vals = np.random.choice(entity_list, size=n)\n",
    "\n",
    "        for i,idx in enumerate(idxs):\n",
    "            rand_corrupted[i,idx] = vals[i]\n",
    "                \n",
    "        return rand_corrupted\n",
    "\n",
    "    def new_corrupt(self, edge_list: torch.Tensor):\n",
    "        \"\"\" sample either the head or tail of x from range(n) \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        # sample random entity replacements\n",
    "        r1 = np.random.choice(entity_list, size=n)\n",
    "        r2 = np.random.choice(entity_list, size=n)\n",
    "\n",
    "        corrupted_heads = edge_list.detach().clone()\n",
    "        corrupted_tails = edge_list.detach().clone()\n",
    "\n",
    "        corrupted_heads[:,0] = torch.from_numpy(r1)\n",
    "        corrupted_tails[:,1] = torch.from_numpy(r2)\n",
    "                \n",
    "        return corrupted_heads, corrupted_tails\n",
    "            \n",
    "\n",
    "    def embedding_loss(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        \n",
    "        loss = torch.zeros(1).to(self.device)\n",
    "\n",
    "        #edge_list_cor = self.corrupt_edge_list(edge_list)\n",
    "        corrupted_heads, corrupted_tails = self.new_corrupt(edge_list)\n",
    "        \n",
    "        # take embedding values for entities and relations\n",
    "        e1 = self.entity_mat.weight[edge_list.repeat(2,1)]\n",
    "        e2 = torch.vstack([self.entity_mat.weight[corrupted_heads],\n",
    "                           self.entity_mat.weight[corrupted_tails]])\n",
    "        l = self.relation_mat.weight[labels].repeat(2,1)\n",
    "\n",
    "        # compute the loss value\n",
    "        n1 = torch.norm(e1[:,0,:] + l - e1[:,1,:], dim=1, p=self.p)\n",
    "        n2 = torch.norm(e2[:,0,:] + l - e2[:,1,:], dim=1, p=self.p)\n",
    "        loss = (self.margin + n1 - n2)\n",
    "        loss = torch.clip(loss, min=0).sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluation_protocol(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        rankings_list = list()\n",
    "        hits_at_10_list = list()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(edge_list.shape[0]):\n",
    "                # take a single test triplet\n",
    "                test_triplet = edge_list[i]\n",
    "\n",
    "                n = self.num_entities\n",
    "\n",
    "                # replicate triplet for num_entities time for corruption\n",
    "                entities = torch.tensor(list(range(self.num_entities)))\n",
    "                x_cor = test_triplet.repeat(n, 1)\n",
    "\n",
    "                # relation embeddings\n",
    "                l = self.relation_mat.weight[labels[i].repeat(n)]\n",
    "\n",
    "                # compute ranking and hits@10 by corrupting both head and tail\n",
    "                for pos in [0,1]:\n",
    "                    # replace triplet head with each possible entities\n",
    "                    x_cor[:, pos] = entities\n",
    "\n",
    "                    # get entity matrix for all possible pairings\n",
    "                    e = self.entity_mat.weight[x_cor]\n",
    "\n",
    "                    # compute distance between head + label and tail\n",
    "                    dissimilarities = torch.norm(e[:,0,:] + l - e[:,1,:], dim=1)\n",
    "\n",
    "                    # rank distances in ascending order\n",
    "                    ranking = torch.argsort(dissimilarities)\n",
    "\n",
    "                    # find position of true triplet within ranking and if is <10\n",
    "                    val = test_triplet[pos] # id of replaced entity\n",
    "                    test_pos = torch.where(ranking == val)[0].item()\n",
    "                    is_among_10 = int(test_pos < 10)\n",
    "\n",
    "                    # save current rank to later compute test results\n",
    "                    rankings_list.append(test_pos)\n",
    "                    hits_at_10_list.append(is_among_10)\n",
    "\n",
    "            mean_rank = np.mean(rankings_list).astype(int)\n",
    "            hits_at_10 = np.mean(hits_at_10_list)*100\n",
    "\n",
    "        return mean_rank, hits_at_10\n",
    "\n",
    "    def new_evaluation_protocol(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        batch_size = edge_list.shape[0]\n",
    "\n",
    "        true_heads, true_tails = edge_list.unbind(dim=1)\n",
    "\n",
    "        # combine heads, tails and labels\n",
    "        x = torch.hstack([edge_list, labels.reshape(-1,1)])\n",
    "\n",
    "        # reorder column as (h,l,t)\n",
    "        idx = torch.tensor([0,2,1]).to(self.device)\n",
    "        x = x.index_select(dim=1, index=idx)\n",
    "\n",
    "        # repeat all triplets for n_entities times\n",
    "        x = x[:,np.newaxis,:].repeat(1,self.num_entities,1)\n",
    "\n",
    "        true_pos_total = list()\n",
    "        rank_pos_list = list()\n",
    "\n",
    "        for pos in [0,1]:\n",
    "            # replace all heads with list of all possible entities\n",
    "            x[:,:,pos] = torch.tensor(range(self.num_entities))[np.newaxis,:].repeat(batch_size,1).to(self.device)\n",
    "\n",
    "            e1 = self.entity_mat.weight[x[:,:,0]]\n",
    "            e2 = self.entity_mat.weight[x[:,:,2]]\n",
    "            l = self.relation_mat.weight[x[:,:,1]]\n",
    "\n",
    "            # compute distance between head + label and tail\n",
    "            norms = torch.norm(e1+l-e2, dim=2, p=self.p)\n",
    "\n",
    "            # get index positions of sorted norms for each triplet\n",
    "            rankings = torch.vstack([torch.argsort(x) for x in norms.unbind(dim=0)])\n",
    "\n",
    "            # find position of heads within the rankings\n",
    "            rank_pos = torch.where(rankings == true_heads.reshape(-1,1))[1]\n",
    "\n",
    "            rank_pos_list.append(rank_pos)\n",
    "            true_pos_total += (rank_pos < 10).sum()\n",
    "\n",
    "        mean_rank = torch.vstack(rank_pos_list).float().mean()\n",
    "        hits_at_10 = torch.vstack(true_pos_total).float().mean()*100\n",
    "\n",
    "        return mean_rank, hits_at_10\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.embedding_loss(batch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.embedding_loss(batch)\n",
    "        mean_rank, hits_at_10 = self.new_evaluation_protocol(batch)\n",
    "        metrics = {\"val_loss\": loss, \"val_mean_rank\": mean_rank, \"val_hits@10\": hits_at_10}\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.embedding_loss(batch)\n",
    "        mean_rank, hits_at_10 = self.evaluation_protocol(batch)\n",
    "        metrics = {\"val_loss\": loss, \"val_mean_rank\": mean_rank, \"val_hits@10\": hits_at_10}\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        with torch.no_grad():\n",
    "             # keep entities embeddings normalized\n",
    "            self.entity_mat.weight.copy_(nn.functional.normalize(self.entity_mat.weight, p=2, dim=1))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory C:\\Users\\Uni\\Desktop\\TransE\\checkpoints\\emb_dim=20-lr=0.01-margin=2 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at checkpoints/emb_dim=20-lr=0.01-margin=2\\transe-wordnet-epoch=3-val_mean_rank=12822.ckpt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[39m{\u001b[39;00mckpt_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_restore_modules_and_callbacks(ckpt_path)\n\u001b[0;32m   1058\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: configuring sharded model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:998\u001b[0m, in \u001b[0;36mTrainer._restore_modules_and_callbacks\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_restore_modules_and_callbacks\u001b[39m(\u001b[39mself\u001b[39m, checkpoint_path: Optional[_PATH] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m     \u001b[39m# restore modules after setup\u001b[39;00m\n\u001b[1;32m--> 998\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_checkpoint_connector\u001b[39m.\u001b[39;49mresume_start(checkpoint_path)\n\u001b[0;32m    999\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_restore_quantization_callbacks()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:90\u001b[0m, in \u001b[0;36mCheckpointConnector.resume_start\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[1;32m---> 90\u001b[0m     loaded_checkpoint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mload_checkpoint(checkpoint_path)\n\u001b[0;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loaded_checkpoint \u001b[39m=\u001b[39m _pl_migrate_checkpoint(loaded_checkpoint, checkpoint_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\strategies\\strategy.py:358\u001b[0m, in \u001b[0;36mStrategy.load_checkpoint\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_checkpoint\u001b[39m(\u001b[39mself\u001b[39m, checkpoint_path: _PATH) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m--> 358\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mempty_cache()\n\u001b[0;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_io\u001b[39m.\u001b[39mload_checkpoint(checkpoint_path)\n",
      "File \u001b[1;32mc:\\Users\\Uni\\miniconda3\\lib\\site-packages\\torch\\cuda\\memory.py:125\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 125\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_emptyCache()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[262], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     ckpt_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, datamodule\u001b[39m=\u001b[39;49mdm, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    610\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\call.py:63\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m logger \u001b[39min\u001b[39;00m trainer\u001b[39m.\u001b[39mloggers:\n\u001b[0;32m     62\u001b[0m     logger\u001b[39m.\u001b[39mfinalize(\u001b[39m\"\u001b[39m\u001b[39mfailed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m trainer\u001b[39m.\u001b[39;49m_teardown()\n\u001b[0;32m     64\u001b[0m \u001b[39m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[0;32m     65\u001b[0m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstage \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1175\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_teardown\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[39m    Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mteardown()\n\u001b[0;32m   1176\u001b[0m     loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_active_loop\n\u001b[0;32m   1177\u001b[0m     \u001b[39m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\strategies\\strategy.py:499\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m    498\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mteardown()\n\u001b[0;32m    500\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_io\u001b[39m.\u001b[39mteardown()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\accelerators\\cuda.py:77\u001b[0m, in \u001b[0;36mCUDAAccelerator.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mteardown\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[39m# clean up memory\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\Uni\\miniconda3\\lib\\site-packages\\torch\\cuda\\memory.py:125\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 125\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_emptyCache()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "emb_dim = 20\n",
    "lr = 0.01\n",
    "margin = 2\n",
    "max_epochs = 1000\n",
    "top_k_cp = 3\n",
    "p = 2   # norm either L1 or L2\n",
    "\n",
    "# instantiated model and data module\n",
    "model = TransE(emb_dim=emb_dim,\n",
    "               learning_rate=lr,\n",
    "               margin=margin, p=p)\n",
    "\n",
    "dm = WordNetDataModule(batch_size=32)\n",
    "\n",
    "dir_path = f\"checkpoints/emb_dim={emb_dim}-lr={lr}-margin={margin}\"\n",
    "\n",
    "# using mean predicted rank on validation set as described in section 4.2\n",
    "early_stop_rank = EarlyStopping(monitor=\"val_mean_rank\",\n",
    "                                min_delta=1,\n",
    "                                patience=10,\n",
    "                                verbose=False,\n",
    "                                mode=\"min\")\n",
    "\n",
    "# save best models based on mean rank on validation set\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=top_k_cp,\n",
    "                                      monitor=\"val_mean_rank\",\n",
    "                                      dirpath=dir_path,\n",
    "                                      filename=\"transe-wordnet-{epoch}-{val_mean_rank:.0f}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[checkpoint_callback,early_stop_rank])\n",
    "\n",
    "try:\n",
    "    # resume from best model if checkpoint is available\n",
    "    ckpt_path = os.path.join(dir_path, os.listdir(dir_path)[-1])\n",
    "except:\n",
    "    ckpt_path = None\n",
    "\n",
    "trainer.fit(model, datamodule=dm, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE.load_from_checkpoint(\"checkpoints/emb_dim=20-lr=0.01-margin=2/transe-wordnet-epoch=21-val_mean_rank=11416.ckpt\", emb_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2]), torch.Size([32]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list, labels = next(iter(dm.val_dataloader()))\n",
    "edge_list.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_protocol(batch,):\n",
    "    edge_list, labels = batch\n",
    "    edge_list = edge_list.to(model.device)\n",
    "    labels = labels.to(model.device)\n",
    "    batch_size = edge_list.shape[0]\n",
    "\n",
    "    # combine heads, tails and labels\n",
    "    x = torch.hstack([edge_list, labels.reshape(-1,1)]).to(model.device)\n",
    "\n",
    "    # reorder column as (h,l,t)\n",
    "    idx = torch.tensor([0,2,1]).to(model.device)\n",
    "    x = x.index_select(dim=1, index=idx)\n",
    "\n",
    "    # repeat all triplets for n_entities times\n",
    "    x = x[:,np.newaxis,:].repeat(1,model.num_entities,1)\n",
    "\n",
    "    true_pos_total = list()\n",
    "    rank_pos_list = list()\n",
    "\n",
    "    for pos in [0,1]:\n",
    "        # replace all heads with list of all possible entities\n",
    "        x[:,:,pos] = torch.tensor(range(model.num_entities))[np.newaxis,:].repeat(batch_size,1).to(model.device)\n",
    "\n",
    "        e1 = model.entity_mat.weight[x[:,:,0]]\n",
    "        e2 = model.entity_mat.weight[x[:,:,2]]\n",
    "        l = model.relation_mat.weight[x[:,:,1]]\n",
    "\n",
    "        # compute distance between head + label and tail\n",
    "        norms = torch.norm(e1+l-e2, dim=2, p=model.p)\n",
    "\n",
    "        # get index positions of sorted norms for each triplet\n",
    "        rankings = torch.vstack([torch.argsort(x) for x in norms.unbind(dim=0)])\n",
    "\n",
    "        # find position of heads within the rankings\n",
    "        rank_pos = torch.where(rankings == edge_list[:,pos].reshape(-1,1))[1]\n",
    "\n",
    "        rank_pos_list.append(rank_pos)\n",
    "        true_pos_total.append((rank_pos < 10).to(model.device))\n",
    "    \n",
    "    return torch.vstack(rank_pos_list).float().mean(), torch.vstack(true_pos_total).float().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[260], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluation_protocol([edge_list, labels])\n",
      "Cell \u001b[1;32mIn[259], line 35\u001b[0m, in \u001b[0;36mevaluation_protocol\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     32\u001b[0m rankings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mvstack([torch\u001b[39m.\u001b[39margsort(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m norms\u001b[39m.\u001b[39munbind(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)])\n\u001b[0;32m     34\u001b[0m \u001b[39m# find position of heads within the rankings\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m rank_pos \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mwhere(rankings \u001b[39m==\u001b[39;49m edge_list[:,pos]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))[\u001b[39m1\u001b[39m]\n\u001b[0;32m     37\u001b[0m rank_pos_list\u001b[39m.\u001b[39mappend(rank_pos)\n\u001b[0;32m     38\u001b[0m true_pos_total\u001b[39m.\u001b[39mappend((rank_pos \u001b[39m<\u001b[39m \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "evaluation_protocol([edge_list, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4321.9062)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 16, 17, 56, 65])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_heads[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5), tensor(16))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings[0][110], rankings[1][31], rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
