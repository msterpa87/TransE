{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write implementation on PyTorch for TransE model (you can use TorchGeometric or DGL library for working with graphs) and train your model on WordNet18RR dataset (you can use loaded dataset from any graph library).\n",
    "\n",
    "As a result, you must provide a link to github (or gitlab) with all the source code.\n",
    "The readability of the code, the presence of comments, type annotations, and the quality of the code as a whole will be taken into account when checking the test case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Callable, Optional, Tuple\n",
    "from contextlib import suppress\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import WordNet18RR, WordNet18\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download wordnet dataset, we'll be using the processed file data.pt\n",
    "dataset = WordNet18('./WordNet18/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# create entity2id and relation2id files\n",
    "DATASET = \"WordNet18\"\n",
    "WORDNET_PATH = f\"./{DATASET}/raw/\"\n",
    "\n",
    "class Edge():\n",
    "    def __init__(self, head, tail, rel) -> None:\n",
    "        self.head = head\n",
    "        self.tail = tail\n",
    "        self.rel = rel\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.head} {self.rel} {self.tail}\"\n",
    "\n",
    "def process_lines(lines, delim='\\t'):\n",
    "    return list(map(lambda s: s.strip('\\n').split(delim), lines))\n",
    "\n",
    "def load_edges_from_file(path: str, is_wn18: bool=True, delim='\\t'):\n",
    "    edge_list = list()\n",
    "\n",
    "    lines = open(path).readlines()\n",
    "\n",
    "    # WN18 contains a header line\n",
    "    if is_wn18:\n",
    "        lines = lines[1:]\n",
    "        delim = ' '\n",
    "\n",
    "    lines = process_lines(lines, delim=delim)\n",
    "\n",
    "    if is_wn18:\n",
    "        edge_list = [Edge(head=head, tail=tail, rel=rel) for head, tail, rel in lines]\n",
    "    else:\n",
    "        edge_list = [Edge(head=head, tail=tail, rel=rel) for head, rel, tail in lines]\n",
    "    \n",
    "    return edge_list\n",
    "\n",
    "def load_ids_dict(path=WORDNET_PATH):\n",
    "    entity2id = process_lines(open(os.path.join(path, \"entity2id.txt\")))\n",
    "    relation2id = process_lines(open(os.path.join(path, \"relation2id.txt\")))\n",
    "\n",
    "    entity2id = dict([(x[0], int(x[1])) for x in entity2id])\n",
    "    relation2id = dict([(x[0], int(x[1])) for x in relation2id])\n",
    "\n",
    "    return entity2id, relation2id\n",
    "\n",
    "is_wn18 = DATASET == \"WordNet18\"\n",
    "print(is_wn18)\n",
    "\n",
    "train_edge_list = load_edges_from_file(os.path.join(WORDNET_PATH, \"train.txt\"), is_wn18=is_wn18)\n",
    "val_edge_list = load_edges_from_file(os.path.join(WORDNET_PATH, \"valid.txt\"), is_wn18=is_wn18)\n",
    "test_edge_list = load_edges_from_file(os.path.join(WORDNET_PATH, \"test.txt\"), is_wn18=is_wn18)\n",
    "\n",
    "entity_list = list()\n",
    "relation_list = list()\n",
    "\n",
    "for edge_list in [train_edge_list, val_edge_list, test_edge_list]:\n",
    "    entity_list += [x.head for x in edge_list] + [x.tail for x in edge_list]\n",
    "    relation_list += [x.rel for x in edge_list]\n",
    "\n",
    "entity_list = sorted(list(set(entity_list)))\n",
    "entity2id = dict(zip(entity_list, range(len(entity_list))))\n",
    "\n",
    "relation_list = sorted(list(set(relation_list)))\n",
    "relation2id = dict(zip(relation_list, range(len(relation_list))))\n",
    "\n",
    "with open(f\"{DATASET}/raw/entity2id.txt\", \"w\") as f:\n",
    "    f.writelines([f\"{x}\\t{y}\\n\" for x,y in entity2id.items()])\n",
    "\n",
    "with open(f\"{DATASET}/raw/relation2id.txt\", \"w\") as f:\n",
    "    f.writelines([f\"{x}\\t{y}\\n\" for x,y in relation2id.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetDataset(Dataset):\n",
    "    def __init__(self, path: str=\"./WordNet18RR/raw/\", split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "\n",
    "        if split == 'val':\n",
    "            split = 'valid'\n",
    "        self.split = split\n",
    "\n",
    "        edge_list = load_edges_from_file(os.path.join(self.path, f\"{self.split}.txt\"))\n",
    "        entity2id, relation2id = load_ids_dict(path=path)\n",
    "\n",
    "        self.edge_list = torch.tensor([(entity2id[e.head], entity2id[e.tail]) for e in edge_list])\n",
    "        self.relation_list = torch.tensor([relation2id[e.rel] for e in edge_list])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.edge_list.shape[0]\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int,int]:\n",
    "        return self.edge_list[index], self.relation_list[index]\n",
    "\n",
    "class WordNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, path: str=\"./WordNet18RR/raw/\", batch_size=32) -> None:\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_entities = 40943\n",
    "        self.num_relations = 11\n",
    "        self.params = {\"pin_memory\": True, \"batch_size\": batch_size}\n",
    "\n",
    "        print(os.getcwd())\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = WordNetDataset(path=self.path, split=\"train\")\n",
    "            self.val_dataset = WordNetDataset(path=self.path, split=\"valid\")\n",
    "        \n",
    "        if stage == \"predict\":\n",
    "            self.test_dataset = WordNetDataset(path=self.path, split=\"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, shuffle=True, **self.params)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, shuffle=False, **self.params)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, shuffle=False, **self.params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(pl.LightningModule):\n",
    "    def __init__(self, margin: int=1, emb_dim: int=50, learning_rate=0.01, p_norm=1) -> None:\n",
    "        \"\"\" Instatiate the entity and relation matrix of the TransE model\n",
    "            https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "\n",
    "        Args:\n",
    "            n_entities (int): _description_\n",
    "            n_relations (int): _description_\n",
    "            margin (int, optional): _description_. Defaults to 1.\n",
    "            emb_dim (int, optional): _description_. Defaults to 50.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.emb_dim = emb_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.p_norm = p_norm\n",
    "\n",
    "        # dataset specific values\n",
    "        self.num_entities = 40943\n",
    "        self.num_relations = 11\n",
    "\n",
    "        # initialize embeddings\n",
    "        self.entity_mat = nn.Embedding(self.num_entities, emb_dim).to(self.device)\n",
    "        self.relation_mat = nn.Embedding(self.num_relations, emb_dim).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # initialize with random uniform\n",
    "            val = 6/np.sqrt(emb_dim)\n",
    "            self.entity_mat.weight.uniform_(-val, val)\n",
    "            self.relation_mat.weight.uniform_(-val, val)\n",
    "\n",
    "            # normalize entity and relation embeddings\n",
    "            self.entity_mat.weight.copy_(F.normalize(self.entity_mat.weight, p=self.p_norm, dim=-1))\n",
    "            self.relation_mat.weight.copy_(F.normalize(self.relation_mat.weight, p=self.p_norm, dim=-1))\n",
    "\n",
    "    def corrupt_edge_list(self, edge_list: torch.Tensor):\n",
    "        \"\"\" sample either the head or tail of x from range(n) \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        # sample random entity replacements\n",
    "        r1 = np.random.choice(entity_list, size=n)\n",
    "        r2 = np.random.choice(entity_list, size=n)\n",
    "\n",
    "        corrupted_heads = edge_list.detach().clone()\n",
    "        corrupted_tails = edge_list.detach().clone()\n",
    "\n",
    "        corrupted_heads[:,0] = torch.from_numpy(r1)\n",
    "        corrupted_tails[:,1] = torch.from_numpy(r2)\n",
    "                \n",
    "        return corrupted_heads, corrupted_tails\n",
    "    \n",
    "    def embedding_loss(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        \n",
    "        loss = torch.zeros(1).to(self.device)\n",
    "\n",
    "        #edge_list_cor = self.corrupt_edge_list(edge_list)\n",
    "        corrupted_heads, corrupted_tails = self.corrupt_edge_list(edge_list)\n",
    "        \n",
    "        # take embedding values for entities and relations\n",
    "        t1 = self.entity_mat.weight[edge_list.repeat(2,1)]\n",
    "        t2 = torch.vstack([self.entity_mat.weight[corrupted_heads],\n",
    "                           self.entity_mat.weight[corrupted_tails]])\n",
    "        rel = self.relation_mat.weight[labels].repeat(2,1)\n",
    "\n",
    "        # normalize entity (maybe unnecessary here)\n",
    "        #t1 = F.normalize(t1, p=self.p_norm, dim=-1)\n",
    "        #t2 = F.normalize(t2, p=self.p_norm, dim=-1)\n",
    "\n",
    "        # compute the loss value\n",
    "        pos = torch.norm(t1[:,0,:] + rel - t1[:,1,:], dim=-1, p=self.p_norm)\n",
    "        neg = torch.norm(t2[:,0,:] + rel - t2[:,1,:], dim=-1, p=self.p_norm)\n",
    "        loss = torch.clip((self.margin + pos - neg), min=0).sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluation_protocol(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        batch_size = edge_list.shape[0]\n",
    "\n",
    "        # combine heads, tails and labels\n",
    "        triplets = torch.hstack([edge_list, labels.reshape(-1,1)])\n",
    "\n",
    "        # repeat all triplets for n_entities times\n",
    "        triplets = triplets[:,np.newaxis,:].repeat(1,self.num_entities,1)\n",
    "\n",
    "        true_pos_total = list()\n",
    "        rank_pos_list = list()\n",
    "\n",
    "        # repeat corruption for both head and tail\n",
    "        for pos in [0,1]:\n",
    "            x = triplets.detach().clone()\n",
    "            \n",
    "            # replace all heads/tails with list of all possible entities\n",
    "            x[:,:,pos] = torch.tensor(range(self.num_entities))[np.newaxis,:].repeat(batch_size,1).to(self.device)\n",
    "\n",
    "            # triplets are arranged as (head, tail, label)\n",
    "            head = self.entity_mat.weight[x[:,:,0]]\n",
    "            tail = self.entity_mat.weight[x[:,:,1]]\n",
    "            rel = self.relation_mat.weight[x[:,:,2]]\n",
    "\n",
    "            # compute distance between head + label and tail\n",
    "            norms = torch.norm(head + rel - tail, dim=-1, p=self.p_norm)\n",
    "\n",
    "            # get index positions of sorted norms for each triplet\n",
    "            rankings = torch.vstack([torch.argsort(x) for x in norms.unbind(dim=0)])\n",
    "\n",
    "            # find position of heads within the rankings\n",
    "            torch.save(rankings, \"rankings.pt\")\n",
    "            torch.save(edge_list, \"edge_list.pt\")\n",
    "            rank_pos = torch.where(rankings == edge_list[:,pos].reshape(-1,1))[1]\n",
    "\n",
    "            rank_pos_list.append(rank_pos)\n",
    "            true_pos_total.append(rank_pos < 10)\n",
    "\n",
    "        mean_rank = torch.vstack(rank_pos_list).float().mean()\n",
    "        hits_at_10 = torch.vstack(true_pos_total).float().mean()*100\n",
    "\n",
    "        return torch.vstack(rank_pos_list).flatten()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.embedding_loss(batch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.embedding_loss(batch)\n",
    "        batch_rankings = self.evaluation_protocol(batch)\n",
    "        self.log_dict({\"val_loss\": loss}, prog_bar=True, on_epoch=True)\n",
    "        return {\"val_loss\": loss, \"batch_rankings\": batch_rankings}\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        mean_rank, hits_at_10 = self.evaluation_protocol(batch)\n",
    "        return mean_rank, hits_at_10\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        with torch.no_grad():\n",
    "             # keep entities embeddings normalized\n",
    "            self.entity_mat.weight.copy_(F.normalize(self.entity_mat.weight, p=2, dim=1))\n",
    "    \n",
    "    def compute_epoch_metrics(self, outputs, stage):\n",
    "        epoch_rankings = torch.hstack([x['batch_rankings'] for x in outputs])\n",
    "        mean_rank = epoch_rankings.float().float().mean()\n",
    "        hit_at_10 = (epoch_rankings < 10).float().mean()*100\n",
    "        self.log_dict({f\"{stage}_mean_rank\": mean_rank, f\"{stage}_hits@10\": hit_at_10},\n",
    "                      prog_bar=True, on_epoch=True)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.compute_epoch_metrics(outputs, stage=\"val\")\n",
    "\n",
    "    def predict_epoch_end(self, outputs):\n",
    "        self.compute_epoch_metrics(outputs, stage=\"predict\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transe(config,\n",
    "                 max_epochs=100,\n",
    "                 accelerator='gpu',\n",
    "                 num_best_ckpt=3,\n",
    "                 patience=10,\n",
    "                 min_delta=0.5,\n",
    "                 main_path='./',\n",
    "                 dataset='WordNet18RR'):\n",
    "    \n",
    "    model = TransE(emb_dim=config['emb_dim'],\n",
    "                learning_rate=config['lr'],\n",
    "                margin=config['margin'],\n",
    "                p_norm=config['p_norm'])\n",
    "\n",
    "    dm = WordNetDataModule(batch_size=config['batch_size'], path=os.path.join(main_path, f\"{dataset}/raw\"))\n",
    "\n",
    "    dir_path = f\"ckpt_{dataset}/emb_dim={config['emb_dim']}-lr={config['lr']}-margin={config['margin']}-p_norm={config['p_norm']}\"\n",
    "    dir_path = os.path.join(main_path, dir_path)\n",
    "\n",
    "    # using mean predicted rank on validation set as described in section 4.2\n",
    "    early_stop_rank = EarlyStopping(monitor=\"val_mean_rank\",\n",
    "                                    min_delta=min_delta,\n",
    "                                    patience=patience,\n",
    "                                    verbose=False,\n",
    "                                    mode=\"min\")\n",
    "\n",
    "    # save best models based on mean rank on validation set\n",
    "    checkpoint_callback = ModelCheckpoint(save_top_k=num_best_ckpt,\n",
    "                                        monitor=\"val_mean_rank\",\n",
    "                                        dirpath=dir_path,\n",
    "                                        filename=\"transe-{dataset}-{epoch}-{val_mean_rank:.0f}-{val_hits@10:.1f}\")\n",
    "\n",
    "    metrics = {\"loss\": \"val_loss\", \"mean_rank\": \"val_mean_rank\"}\n",
    "\n",
    "    logger = TensorBoardLogger(f'tb_logs_{dataset}', name='TransE')\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                        accelerator=accelerator,\n",
    "                        callbacks=[checkpoint_callback, early_stop_rank],\n",
    "                        logger=logger)\n",
    "\n",
    "    try:\n",
    "        # resume from best model if checkpoint is available\n",
    "        ckpt_path = os.path.join(dir_path, os.listdir(dir_path)[-1])\n",
    "    except:\n",
    "        ckpt_path = None\n",
    "\n",
    "    trainer.fit(model, datamodule=dm, ckpt_path=ckpt_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory C:\\Users\\Uni\\Desktop\\TransE\\checkpoints\\emb_dim=30-lr=0.001-margin=1-p_norm=2 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at ./checkpoints/emb_dim=30-lr=0.001-margin=1-p_norm=2\\transe-wordnet-epoch=99-val_mean_rank=2500-val_hits@10=39.5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:26<00:00, 53.05it/s, loss=91, v_num=55, val_loss=133.0, val_mean_rank=3.56e+3, val_hits@10=36.90]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:26<00:00, 52.96it/s, loss=91, v_num=55, val_loss=133.0, val_mean_rank=3.56e+3, val_hits@10=36.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.87it/s, loss=1.11e+03, v_num=56, val_loss=1.15e+3, val_mean_rank=3.6e+3, val_hits@10=36.20] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.79it/s, loss=1.11e+03, v_num=56, val_loss=1.15e+3, val_mean_rank=3.6e+3, val_hits@10=36.20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 440   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.553     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 50.67it/s, loss=7.85, v_num=57, val_loss=37.20, val_mean_rank=2.86e+3, val_hits@10=41.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 50.55it/s, loss=7.85, v_num=57, val_loss=37.20, val_mean_rank=2.86e+3, val_hits@10=41.40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 440   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.553     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.72it/s, loss=86.4, v_num=58, val_loss=126.0, val_mean_rank=3.31e+3, val_hits@10=37.40]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.60it/s, loss=86.4, v_num=58, val_loss=126.0, val_mean_rank=3.31e+3, val_hits@10=37.40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 440   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.553     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 52.03it/s, loss=1.1e+03, v_num=59, val_loss=1.14e+3, val_mean_rank=3.41e+3, val_hits@10=36.50] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.91it/s, loss=1.1e+03, v_num=59, val_loss=1.14e+3, val_mean_rank=3.41e+3, val_hits@10=36.50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:25<00:00, 54.66it/s, loss=8.15, v_num=60, val_loss=28.90, val_mean_rank=2.85e+3, val_hits@10=32.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:25<00:00, 54.57it/s, loss=8.15, v_num=60, val_loss=28.90, val_mean_rank=2.85e+3, val_hits@10=32.70]\n",
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:25<00:00, 54.77it/s, loss=41.4, v_num=61, val_loss=75.90, val_mean_rank=2.76e+3, val_hits@10=31.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:25<00:00, 54.68it/s, loss=41.4, v_num=61, val_loss=75.90, val_mean_rank=2.76e+3, val_hits@10=31.70]\n",
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.09it/s, loss=1.01e+03, v_num=62, val_loss=1.06e+3, val_mean_rank=8.23e+3, val_hits@10=24.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.09it/s, loss=1.01e+03, v_num=62, val_loss=1.06e+3, val_mean_rank=8.23e+3, val_hits@10=24.20]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 440   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.553     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 1405/1405 [00:27<00:00, 51.51it/s, loss=7.14, v_num=63, val_loss=28.80, val_mean_rank=2.83e+3, val_hits@10=33.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 440   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.553     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.90it/s, loss=38.6, v_num=64, val_loss=72.00, val_mean_rank=2.7e+3, val_hits@10=32.60] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 1405/1405 [00:27<00:00, 51.78it/s, loss=38.6, v_num=64, val_loss=72.00, val_mean_rank=2.7e+3, val_hits@10=32.60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.6 M \n",
      "1 | relation_mat | Embedding | 440   \n",
      "-------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.553     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 1405/1405 [00:31<00:00, 44.37it/s, loss=1.01e+03, v_num=65, val_loss=1.05e+3, val_mean_rank=8.41e+3, val_hits@10=23.10]\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"batch_size\": [64],\n",
    "    \"lr\": [0.001, 0.005],\n",
    "    \"emb_dim\": [30, 40],\n",
    "    \"p_norm\": [2],\n",
    "    \"margin\": [1, 2, 10]\n",
    "}\n",
    "\n",
    "import itertools\n",
    "\n",
    "keys, values = zip(*config.items())\n",
    "comb_list = [dict(zip(keys,v)) for v in itertools.product(*values)]\n",
    "\n",
    "for comb in comb_list:\n",
    "    try:\n",
    "        train_transe(config=comb, max_epochs=50)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Uni\\Desktop\\TransE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 1.2 M \n",
      "1 | relation_mat | Embedding | 330   \n",
      "-------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.914     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m )\n\u001b[1;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1203\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1206\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m-> 1276\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[0;32m    154\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1494\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1496\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[5], line 127\u001b[0m, in \u001b[0;36mTransE.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    126\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_loss(batch)\n\u001b[1;32m--> 127\u001b[0m batch_rankings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluation_protocol(batch)\n\u001b[0;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_dict({\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m: loss}, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, on_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 93\u001b[0m, in \u001b[0;36mTransE.evaluation_protocol\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mfor\u001b[39;00m pos \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]:\n\u001b[1;32m---> 93\u001b[0m     x \u001b[39m=\u001b[39m triplets\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m     95\u001b[0m     \u001b[39m# replace all heads/tails with list of all possible entities\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m single_train_config \u001b[39m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m64\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmargin\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m\n\u001b[0;32m      7\u001b[0m }\n\u001b[1;32m----> 9\u001b[0m train_transe(config\u001b[39m=\u001b[39;49msingle_train_config, dataset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWordNet18\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[6], line 48\u001b[0m, in \u001b[0;36mtrain_transe\u001b[1;34m(config, max_epochs, accelerator, num_best_ckpt, patience, min_delta, main_path, dataset)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     ckpt_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, datamodule\u001b[39m=\u001b[39;49mdm, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[0;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    610\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\call.py:63\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mfor\u001b[39;00m logger \u001b[39min\u001b[39;00m trainer\u001b[39m.\u001b[39mloggers:\n\u001b[0;32m     62\u001b[0m     logger\u001b[39m.\u001b[39mfinalize(\u001b[39m\"\u001b[39m\u001b[39mfailed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m trainer\u001b[39m.\u001b[39;49m_teardown()\n\u001b[0;32m     64\u001b[0m \u001b[39m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[0;32m     65\u001b[0m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstage \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1175\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_teardown\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[39m    Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mteardown()\n\u001b[0;32m   1176\u001b[0m     loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_active_loop\n\u001b[0;32m   1177\u001b[0m     \u001b[39m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\strategies\\strategy.py:496\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m     log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: moving model to CPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 496\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mcpu()\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mteardown()\n\u001b[0;32m    498\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning_fabric\\utilities\\device_dtype_mixin.py:78\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cpu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__update_properties(device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcpu()\n",
      "File \u001b[1;32mc:\\Users\\Uni\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:796\u001b[0m, in \u001b[0;36mModule.cpu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcpu\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    788\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcpu())\n",
      "File \u001b[1;32mc:\\Users\\Uni\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:639\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    638\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 639\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    641\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    642\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    643\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    644\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    650\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Uni\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:662\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 662\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    663\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\Uni\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:796\u001b[0m, in \u001b[0;36mModule.cpu.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcpu\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    788\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \n\u001b[0;32m    790\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcpu())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "single_train_config = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.001,\n",
    "    'emb_dim': 30,\n",
    "    'p_norm': 2,\n",
    "    'margin': 1\n",
    "}\n",
    "\n",
    "train_transe(config=single_train_config, dataset=\"WordNet18\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at checkpoints/emb_dim=20-lr=0.01-margin=1-p_norm=2\\transe-wordnet-epoch=0-val_mean_rank=20402-val_hits@10=0.0.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at checkpoints/emb_dim=20-lr=0.01-margin=1-p_norm=2\\transe-wordnet-epoch=0-val_mean_rank=20402-val_hits@10=0.0.ckpt\n",
      "C:\\Users\\Uni\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 98/98 [00:06<00:00, 14.84it/s]\n",
      "test_mean_rank=20634, test_hits@10=0.03\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(model, datamodule=dm, ckpt_path=ckpt_path)\n",
    "test_mean_rank, test_hits_at_10 = torch.tensor(pred).mean(0)\n",
    "print(\"\\n\")\n",
    "print(f\"test_mean_rank={test_mean_rank:.0f}, test_hits@10={test_hits_at_10:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 20\n",
    "lr = 0.01\n",
    "margin = 1\n",
    "max_epochs = 1000\n",
    "top_k_cp = 3\n",
    "p_norm = 2   # norm either L1 or L2\n",
    "\n",
    "# instantiated model and data module\n",
    "model = TransE(emb_dim=emb_dim,\n",
    "               learning_rate=lr,\n",
    "               margin=margin,\n",
    "               p_norm=p_norm)\n",
    "\n",
    "dm = WordNetDataModule(batch_size=32)\n",
    "\n",
    "dir_path = f\"checkpoints/emb_dim={emb_dim}-lr={lr}-margin={margin}-p_norm={p_norm}\"\n",
    "\n",
    "# using mean predicted rank on validation set as described in section 4.2\n",
    "early_stop_rank = EarlyStopping(monitor=\"val_mean_rank\",\n",
    "                                min_delta=0.5,\n",
    "                                patience=10,\n",
    "                                verbose=False,\n",
    "                                mode=\"min\")\n",
    "\n",
    "# save best models based on mean rank on validation set\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=top_k_cp,\n",
    "                                      monitor=\"val_mean_rank\",\n",
    "                                      dirpath=dir_path,\n",
    "                                      filename=\"transe-wordnet-{epoch}-{val_mean_rank:.0f}-{val_hits@10:.1f}\")\n",
    "\n",
    "logger = TensorBoardLogger('tb_logs', name='TransE')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[checkpoint_callback, early_stop_rank],\n",
    "                     logger=logger)\n",
    "\n",
    "try:\n",
    "    # resume from best model if checkpoint is available\n",
    "    ckpt_path = os.path.join(dir_path, os.listdir(dir_path)[-1])\n",
    "except:\n",
    "    ckpt_path = None\n",
    "\n",
    "trainer.fit(model, datamodule=dm, ckpt_path=ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
