{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write implementation on PyTorch for TransE model (you can use TorchGeometric or DGL library for working with graphs) and train your model on WordNet18RR dataset (you can use loaded dataset from any graph library).\n",
    "\n",
    "As a result, you must provide a link to github (or gitlab) with all the source code.\n",
    "The readability of the code, the presence of comments, type annotations, and the quality of the code as a whole will be taken into account when checking the test case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union, Callable, Optional\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch_geometric.datasets import WordNet18RR\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download wordnet dataset, we'll be using the processed file data.pt\n",
    "dataset = WordNet18RR('./WordNet18RR/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Edge():\n",
    "    def __init__(self, u, v, label) -> None:\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.label = label\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.u} {self.label} {self.v}\"\n",
    "\n",
    "def load_edge_list_from_file(path: str, header: bool=False):\n",
    "    edge_list = list()\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        tsv_reader = csv.reader(f, delimiter=\"\\t\")\n",
    "\n",
    "        if header:\n",
    "            next(tsv_reader)\n",
    "\n",
    "        for row in tsv_reader:\n",
    "            u, label, v = row\n",
    "            edge_list.append(Edge(u=u, v=v, label=label))\n",
    "    \n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetEdgeDataset(Dataset):\n",
    "    def __init__(self, path: str=\"WordNet18RR/processed/data.pt\", split: str=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        data = torch.load(path)[0]\n",
    "        mask_dict = {\"train\": data.train_mask, \"test\": data.test_mask, \"val\": data.val_mask}\n",
    "        mask = mask_dict[split]\n",
    "        self.edge_list = data.edge_index.T[mask, :]\n",
    "        self.edge_labels = data.edge_type[mask]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.edge_list.shape[0]\n",
    "\n",
    "    def __getitem__(self, index) -> int:\n",
    "        return self.edge_list[index,:], self.edge_labels[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str=\"WordNet18RR/processed/data.pt\", batch_size=32) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_entities = 40943\n",
    "        self.num_relations = 11\n",
    "        self.params = {\"pin_memory\": True, \"batch_size\": batch_size}\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = WordNetEdgeDataset(split=\"train\", path=self.data_dir)\n",
    "            self.val_dataset = WordNetEdgeDataset(split=\"val\", path=self.data_dir)\n",
    "        \n",
    "        if stage == \"test\":\n",
    "            self.test_dataset = WordNetEdgeDataset(split=\"test\", path=self.data_dir)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, shuffle=True, **self.params)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, shuffle=False, **self.params)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, shuffle=False, **self.params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(pl.LightningModule):\n",
    "    def __init__(self, margin: int=1, emb_dim: int=50, learning_rate=0.01) -> None:\n",
    "        \"\"\" Instatiate the entity and relation matrix of the TransE model\n",
    "            https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data\n",
    "\n",
    "        Args:\n",
    "            n_entities (int): _description_\n",
    "            n_relations (int): _description_\n",
    "            margin (int, optional): _description_. Defaults to 1.\n",
    "            emb_dim (int, optional): _description_. Defaults to 50.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.emb_dim = emb_dim\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # dataset specific values\n",
    "        self.num_entities = 40943\n",
    "        self.num_relations = 11\n",
    "\n",
    "        # initialize embeddings\n",
    "        self.entity_mat = nn.Embedding(self.num_entities, emb_dim).to(self.device)\n",
    "        self.relation_mat = nn.Embedding(self.num_relations, emb_dim).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # initialize with random uniform\n",
    "            val = 6/np.sqrt(emb_dim)\n",
    "            self.entity_mat.weight.uniform_(-val, val)\n",
    "            self.relation_mat.weight.uniform_(-val, val)\n",
    "\n",
    "            # normalize entity embeddings\n",
    "            self.entity_mat.weight.copy_(nn.functional.normalize(self.entity_mat.weight, p=2, dim=1))\n",
    "\n",
    "    def corrupt_edge_list(self, edge_list: torch.Tensor):\n",
    "        \"\"\" sample either the head or tail of x from range(n) \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        idxs = (np.random.rand(edge_list.shape[0]) < 0.5).astype(int)  # pick either head or tail\n",
    "        # sample random entity replacements\n",
    "        rand_corrupted = edge_list.detach().clone()\n",
    "        vals = np.random.choice(entity_list, size=n)\n",
    "\n",
    "        for i,idx in enumerate(idxs):\n",
    "            rand_corrupted[i,idx] = vals[i]\n",
    "                \n",
    "        return rand_corrupted\n",
    "\n",
    "    def new_corrupt(self, edge_list: torch.Tensor):\n",
    "        \"\"\" sample either the head or tail of x from range(n) \"\"\"\n",
    "        n = edge_list.shape[0]\n",
    "        entity_list = range(self.num_entities)\n",
    "\n",
    "        # sample random entity replacements\n",
    "        r1 = np.random.choice(entity_list, size=n)\n",
    "        r2 = np.random.choice(entity_list, size=n)\n",
    "\n",
    "        corrupted_heads = edge_list.detach().clone()\n",
    "        corrupted_tails = edge_list.detach().clone()\n",
    "\n",
    "        corrupted_heads[:,0] = torch.from_numpy(r1)\n",
    "        corrupted_tails[:,1] = torch.from_numpy(r2)\n",
    "                \n",
    "        return corrupted_heads, corrupted_tails\n",
    "            \n",
    "\n",
    "    def embedding_loss(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        \n",
    "        loss = torch.zeros(1).to(self.device)\n",
    "\n",
    "        #edge_list_cor = self.corrupt_edge_list(edge_list)\n",
    "        corrupted_heads, corrupted_tails = self.new_corrupt(edge_list)\n",
    "        \n",
    "        # take embedding values for entities and relations\n",
    "        e1 = self.entity_mat.weight[edge_list.repeat(2,1)]\n",
    "        e2 = torch.vstack([self.entity_mat.weight[corrupted_heads],\n",
    "                           self.entity_mat.weight[corrupted_tails]])\n",
    "        l = self.relation_mat.weight[labels].repeat(2,1)\n",
    "\n",
    "        # compute the loss value\n",
    "        n1 = torch.norm(e1[:,0,:] + l - e1[:,1,:], dim=1)\n",
    "        n2 = torch.norm(e2[:,0,:] + l - e2[:,1,:], dim=1)\n",
    "        loss = (self.margin + n1 - n2)\n",
    "        loss = torch.clip(loss, min=0).sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluation_protocol(self, batch):\n",
    "        edge_list, labels = batch\n",
    "        rankings_list = list()\n",
    "        hits_at_10_list = list()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(edge_list.shape[0]):\n",
    "                # take a single test triplet\n",
    "                test_triplet = edge_list[i]\n",
    "\n",
    "                n = self.num_entities\n",
    "\n",
    "                # replicate triplet for num_entities time for corruption\n",
    "                entities = torch.tensor(list(range(self.num_entities)))\n",
    "                x_cor = test_triplet.repeat(n, 1)\n",
    "\n",
    "                # relation embeddings\n",
    "                l = self.relation_mat.weight[labels[i].repeat(n)]\n",
    "\n",
    "                # compute ranking and hits@10 by corrupting both head and tail\n",
    "                for pos in [0,1]:\n",
    "                    # replace triplet head with each possible entities\n",
    "                    x_cor[:, pos] = entities\n",
    "\n",
    "                    # get entity matrix for all possible pairings\n",
    "                    e = self.entity_mat.weight[x_cor]\n",
    "\n",
    "                    # compute distance between head + label and tail\n",
    "                    dissimilarities = torch.norm(e[:,0,:] + l - e[:,1,:], dim=1)\n",
    "\n",
    "                    # rank distances in ascending order\n",
    "                    ranking = torch.argsort(dissimilarities)\n",
    "\n",
    "                    # find position of true triplet within ranking and if is <10\n",
    "                    val = test_triplet[pos] # id of replaced entity\n",
    "                    test_pos = torch.where(ranking == val)[0].item()\n",
    "                    is_among_10 = int(test_pos < 10)\n",
    "\n",
    "                    # save current rank to later compute test results\n",
    "                    rankings_list.append(test_pos)\n",
    "                    hits_at_10_list.append(is_among_10)\n",
    "\n",
    "            mean_rank = np.mean(rankings_list).astype(int)\n",
    "            hits_at_10 = np.mean(hits_at_10_list)*100\n",
    "\n",
    "        return mean_rank, hits_at_10\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.embedding_loss(batch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.embedding_loss(batch)\n",
    "        mean_rank, hits_at_10 = self.evaluation_protocol(batch)\n",
    "        metrics = {\"val_loss\": loss, \"val_mean_rank\": mean_rank, \"val_hits@10\": hits_at_10}\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.embedding_loss(batch)\n",
    "        mean_rank, hits_at_10 = self.evaluation_protocol(batch)\n",
    "        metrics = {\"val_loss\": loss, \"val_mean_rank\": mean_rank, \"val_hits@10\": hits_at_10}\n",
    "        self.log_dict(metrics, prog_bar=True, on_epoch=True)\n",
    "        return metrics\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        with torch.no_grad():\n",
    "             # keep entities embeddings normalized\n",
    "            self.entity_mat.weight.copy_(nn.functional.normalize(self.entity_mat.weight, p=2, dim=1))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type      | Params\n",
      "-------------------------------------------\n",
      "0 | entity_mat   | Embedding | 818 K \n",
      "1 | relation_mat | Embedding | 220   \n",
      "-------------------------------------------\n",
      "819 K     Trainable params\n",
      "0         Non-trainable params\n",
      "819 K     Total params\n",
      "3.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  98%|█████████▊| 2751/2809 [01:03<00:01, 43.51it/s, loss=21.7, v_num=17, val_loss=37.40, val_mean_rank=1.19e+4, val_hits@10=11.70]"
     ]
    }
   ],
   "source": [
    "emb_dim = 20\n",
    "lr = 0.01\n",
    "margin = 2\n",
    "max_epochs = 1000\n",
    "top_k_cp = 3\n",
    "\n",
    "# instantiated model and data module\n",
    "model = TransE(emb_dim=emb_dim,\n",
    "               learning_rate=lr,\n",
    "               margin=margin)\n",
    "\n",
    "dm = WordNetDataModule(batch_size=32)\n",
    "\n",
    "dir_path = f\"checkpoints/emb_dim={emb_dim}-lr={lr}-margin={margin}\"\n",
    "\n",
    "# using mean predicted rank on validation set as described in section 4.2\n",
    "early_stop_rank = EarlyStopping(monitor=\"val_mean_rank\",\n",
    "                                min_delta=1,\n",
    "                                patience=10,\n",
    "                                verbose=False,\n",
    "                                mode=\"min\")\n",
    "\n",
    "# save best models based on mean rank on validation set\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=top_k_cp,\n",
    "                                      monitor=\"val_mean_rank\",\n",
    "                                      dirpath=dir_path,\n",
    "                                      filename=\"transe-wordnet-{epoch}-{val_mean_rank:.0f}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     accelerator='gpu',\n",
    "                     callbacks=[checkpoint_callback,early_stop_rank])\n",
    "\n",
    "try:\n",
    "    # resume from best model if checkpoint is available\n",
    "    ckpt_path = os.path.join(dir_path, os.listdir(dir_path)[-1])\n",
    "except:\n",
    "    ckpt_path = None\n",
    "\n",
    "trainer.fit(model, datamodule=dm, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE.load_from_checkpoint(\"checkpoints/emb_dim=20-lr=0.01-margin=2/transe-wordnet-epoch=21-val_mean_rank=11416.ckpt\", emb_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2]), torch.Size([32]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list, labels = next(iter(dm.val_dataloader()))\n",
    "edge_list.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    5,  5017,     5],\n",
      "        [   16, 15600,     5],\n",
      "        [   17,  6474,     0],\n",
      "        [   56,  6706,     2],\n",
      "        [   65, 15435,     9],\n",
      "        [   66, 25409,     6],\n",
      "        [   66, 35038,     2],\n",
      "        [   67, 11910,     3],\n",
      "        [   79, 25354,     9],\n",
      "        [   94, 34965,     1],\n",
      "        [  111,  5046,     0],\n",
      "        [  116, 33359,     3],\n",
      "        [  137, 21357,     6],\n",
      "        [  137, 40714,     2],\n",
      "        [  153, 11750,     3],\n",
      "        [  178, 34774,     5],\n",
      "        [  179, 19488,     1],\n",
      "        [  207, 16541,     5],\n",
      "        [  210,  1738,    10],\n",
      "        [  222, 29624,     1],\n",
      "        [  228, 13681,     5],\n",
      "        [  236, 32687,     2],\n",
      "        [  265, 30822,     2],\n",
      "        [  289, 33885,     5],\n",
      "        [  314,  3803,     2],\n",
      "        [  318, 11704,     1],\n",
      "        [  322, 25849,     1],\n",
      "        [  325, 29115,     6],\n",
      "        [  348, 22775,     7],\n",
      "        [  348, 36578,     7],\n",
      "        [  374,  4624,     1],\n",
      "        [  395, 12852,     3]])\n",
      "tensor([[    5,     5,  5017],\n",
      "        [   16,     5, 15600],\n",
      "        [   17,     0,  6474],\n",
      "        [   56,     2,  6706],\n",
      "        [   65,     9, 15435],\n",
      "        [   66,     6, 25409],\n",
      "        [   66,     2, 35038],\n",
      "        [   67,     3, 11910],\n",
      "        [   79,     9, 25354],\n",
      "        [   94,     1, 34965],\n",
      "        [  111,     0,  5046],\n",
      "        [  116,     3, 33359],\n",
      "        [  137,     6, 21357],\n",
      "        [  137,     2, 40714],\n",
      "        [  153,     3, 11750],\n",
      "        [  178,     5, 34774],\n",
      "        [  179,     1, 19488],\n",
      "        [  207,     5, 16541],\n",
      "        [  210,    10,  1738],\n",
      "        [  222,     1, 29624],\n",
      "        [  228,     5, 13681],\n",
      "        [  236,     2, 32687],\n",
      "        [  265,     2, 30822],\n",
      "        [  289,     5, 33885],\n",
      "        [  314,     2,  3803],\n",
      "        [  318,     1, 11704],\n",
      "        [  322,     1, 25849],\n",
      "        [  325,     6, 29115],\n",
      "        [  348,     7, 22775],\n",
      "        [  348,     7, 36578],\n",
      "        [  374,     1,  4624],\n",
      "        [  395,     3, 12852]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.hstack([edge_list, labels.reshape(-1,1)])\n",
    "print(x)\n",
    "x = x.index_select(dim=1, index=torch.tensor([0,2,1]))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    5,     5,  5017],\n",
       "         [    5,     5,  5017],\n",
       "         [    5,     5,  5017],\n",
       "         [    5,     5,  5017],\n",
       "         [    5,     5,  5017]],\n",
       "\n",
       "        [[   16,     5, 15600],\n",
       "         [   16,     5, 15600],\n",
       "         [   16,     5, 15600],\n",
       "         [   16,     5, 15600],\n",
       "         [   16,     5, 15600]],\n",
       "\n",
       "        [[   17,     0,  6474],\n",
       "         [   17,     0,  6474],\n",
       "         [   17,     0,  6474],\n",
       "         [   17,     0,  6474],\n",
       "         [   17,     0,  6474]],\n",
       "\n",
       "        [[   56,     2,  6706],\n",
       "         [   56,     2,  6706],\n",
       "         [   56,     2,  6706],\n",
       "         [   56,     2,  6706],\n",
       "         [   56,     2,  6706]],\n",
       "\n",
       "        [[   65,     9, 15435],\n",
       "         [   65,     9, 15435],\n",
       "         [   65,     9, 15435],\n",
       "         [   65,     9, 15435],\n",
       "         [   65,     9, 15435]],\n",
       "\n",
       "        [[   66,     6, 25409],\n",
       "         [   66,     6, 25409],\n",
       "         [   66,     6, 25409],\n",
       "         [   66,     6, 25409],\n",
       "         [   66,     6, 25409]],\n",
       "\n",
       "        [[   66,     2, 35038],\n",
       "         [   66,     2, 35038],\n",
       "         [   66,     2, 35038],\n",
       "         [   66,     2, 35038],\n",
       "         [   66,     2, 35038]],\n",
       "\n",
       "        [[   67,     3, 11910],\n",
       "         [   67,     3, 11910],\n",
       "         [   67,     3, 11910],\n",
       "         [   67,     3, 11910],\n",
       "         [   67,     3, 11910]],\n",
       "\n",
       "        [[   79,     9, 25354],\n",
       "         [   79,     9, 25354],\n",
       "         [   79,     9, 25354],\n",
       "         [   79,     9, 25354],\n",
       "         [   79,     9, 25354]],\n",
       "\n",
       "        [[   94,     1, 34965],\n",
       "         [   94,     1, 34965],\n",
       "         [   94,     1, 34965],\n",
       "         [   94,     1, 34965],\n",
       "         [   94,     1, 34965]],\n",
       "\n",
       "        [[  111,     0,  5046],\n",
       "         [  111,     0,  5046],\n",
       "         [  111,     0,  5046],\n",
       "         [  111,     0,  5046],\n",
       "         [  111,     0,  5046]],\n",
       "\n",
       "        [[  116,     3, 33359],\n",
       "         [  116,     3, 33359],\n",
       "         [  116,     3, 33359],\n",
       "         [  116,     3, 33359],\n",
       "         [  116,     3, 33359]],\n",
       "\n",
       "        [[  137,     6, 21357],\n",
       "         [  137,     6, 21357],\n",
       "         [  137,     6, 21357],\n",
       "         [  137,     6, 21357],\n",
       "         [  137,     6, 21357]],\n",
       "\n",
       "        [[  137,     2, 40714],\n",
       "         [  137,     2, 40714],\n",
       "         [  137,     2, 40714],\n",
       "         [  137,     2, 40714],\n",
       "         [  137,     2, 40714]],\n",
       "\n",
       "        [[  153,     3, 11750],\n",
       "         [  153,     3, 11750],\n",
       "         [  153,     3, 11750],\n",
       "         [  153,     3, 11750],\n",
       "         [  153,     3, 11750]],\n",
       "\n",
       "        [[  178,     5, 34774],\n",
       "         [  178,     5, 34774],\n",
       "         [  178,     5, 34774],\n",
       "         [  178,     5, 34774],\n",
       "         [  178,     5, 34774]],\n",
       "\n",
       "        [[  179,     1, 19488],\n",
       "         [  179,     1, 19488],\n",
       "         [  179,     1, 19488],\n",
       "         [  179,     1, 19488],\n",
       "         [  179,     1, 19488]],\n",
       "\n",
       "        [[  207,     5, 16541],\n",
       "         [  207,     5, 16541],\n",
       "         [  207,     5, 16541],\n",
       "         [  207,     5, 16541],\n",
       "         [  207,     5, 16541]],\n",
       "\n",
       "        [[  210,    10,  1738],\n",
       "         [  210,    10,  1738],\n",
       "         [  210,    10,  1738],\n",
       "         [  210,    10,  1738],\n",
       "         [  210,    10,  1738]],\n",
       "\n",
       "        [[  222,     1, 29624],\n",
       "         [  222,     1, 29624],\n",
       "         [  222,     1, 29624],\n",
       "         [  222,     1, 29624],\n",
       "         [  222,     1, 29624]],\n",
       "\n",
       "        [[  228,     5, 13681],\n",
       "         [  228,     5, 13681],\n",
       "         [  228,     5, 13681],\n",
       "         [  228,     5, 13681],\n",
       "         [  228,     5, 13681]],\n",
       "\n",
       "        [[  236,     2, 32687],\n",
       "         [  236,     2, 32687],\n",
       "         [  236,     2, 32687],\n",
       "         [  236,     2, 32687],\n",
       "         [  236,     2, 32687]],\n",
       "\n",
       "        [[  265,     2, 30822],\n",
       "         [  265,     2, 30822],\n",
       "         [  265,     2, 30822],\n",
       "         [  265,     2, 30822],\n",
       "         [  265,     2, 30822]],\n",
       "\n",
       "        [[  289,     5, 33885],\n",
       "         [  289,     5, 33885],\n",
       "         [  289,     5, 33885],\n",
       "         [  289,     5, 33885],\n",
       "         [  289,     5, 33885]],\n",
       "\n",
       "        [[  314,     2,  3803],\n",
       "         [  314,     2,  3803],\n",
       "         [  314,     2,  3803],\n",
       "         [  314,     2,  3803],\n",
       "         [  314,     2,  3803]],\n",
       "\n",
       "        [[  318,     1, 11704],\n",
       "         [  318,     1, 11704],\n",
       "         [  318,     1, 11704],\n",
       "         [  318,     1, 11704],\n",
       "         [  318,     1, 11704]],\n",
       "\n",
       "        [[  322,     1, 25849],\n",
       "         [  322,     1, 25849],\n",
       "         [  322,     1, 25849],\n",
       "         [  322,     1, 25849],\n",
       "         [  322,     1, 25849]],\n",
       "\n",
       "        [[  325,     6, 29115],\n",
       "         [  325,     6, 29115],\n",
       "         [  325,     6, 29115],\n",
       "         [  325,     6, 29115],\n",
       "         [  325,     6, 29115]],\n",
       "\n",
       "        [[  348,     7, 22775],\n",
       "         [  348,     7, 22775],\n",
       "         [  348,     7, 22775],\n",
       "         [  348,     7, 22775],\n",
       "         [  348,     7, 22775]],\n",
       "\n",
       "        [[  348,     7, 36578],\n",
       "         [  348,     7, 36578],\n",
       "         [  348,     7, 36578],\n",
       "         [  348,     7, 36578],\n",
       "         [  348,     7, 36578]],\n",
       "\n",
       "        [[  374,     1,  4624],\n",
       "         [  374,     1,  4624],\n",
       "         [  374,     1,  4624],\n",
       "         [  374,     1,  4624],\n",
       "         [  374,     1,  4624]],\n",
       "\n",
       "        [[  395,     3, 12852],\n",
       "         [  395,     3, 12852],\n",
       "         [  395,     3, 12852],\n",
       "         [  395,     3, 12852],\n",
       "         [  395,     3, 12852]]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (batch_size, n_entities, 3)\n",
    "x = x[:,np.newaxis,:].repeat(1,5,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all heads with list of all possible entities\n",
    "x[:,:,0] = torch.tensor(range(5))[np.newaxis,:].repeat(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = model.entity_mat.weight[x[:,:,0]]\n",
    "e2 = model.entity_mat.weight[x[:,:,2]]\n",
    "l = model.relation_mat.weight[x[:,:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 5, 20]), torch.Size([32, 5, 20]), torch.Size([32, 5, 20]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.shape, l.shape, e2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms = torch.norm(e1+l-e2, dim=2)\n",
    "norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([3, 1, 2, 4, 0]),\n",
       " tensor([1, 2, 3, 4, 0]),\n",
       " tensor([4, 1, 2, 3, 0]),\n",
       " tensor([3, 2, 4, 1, 0]),\n",
       " tensor([0, 4, 1, 3, 2]),\n",
       " tensor([2, 3, 1, 4, 0]),\n",
       " tensor([4, 1, 0, 2, 3]),\n",
       " tensor([1, 0, 4, 3, 2]),\n",
       " tensor([0, 1, 3, 4, 2]),\n",
       " tensor([4, 3, 2, 1, 0]),\n",
       " tensor([4, 1, 3, 2, 0]),\n",
       " tensor([1, 4, 3, 2, 0]),\n",
       " tensor([3, 2, 4, 1, 0]),\n",
       " tensor([2, 4, 1, 3, 0]),\n",
       " tensor([0, 4, 3, 1, 2]),\n",
       " tensor([3, 2, 1, 4, 0]),\n",
       " tensor([4, 2, 1, 3, 0]),\n",
       " tensor([3, 2, 4, 1, 0]),\n",
       " tensor([1, 4, 0, 3, 2]),\n",
       " tensor([1, 2, 3, 0, 4]),\n",
       " tensor([3, 1, 2, 4, 0]),\n",
       " tensor([1, 4, 3, 0, 2]),\n",
       " tensor([3, 1, 4, 2, 0]),\n",
       " tensor([3, 2, 1, 4, 0]),\n",
       " tensor([3, 4, 2, 1, 0]),\n",
       " tensor([4, 0, 1, 3, 2]),\n",
       " tensor([1, 0, 3, 4, 2]),\n",
       " tensor([3, 2, 1, 4, 0]),\n",
       " tensor([4, 2, 3, 1, 0]),\n",
       " tensor([2, 4, 3, 1, 0]),\n",
       " tensor([1, 4, 0, 3, 2]),\n",
       " tensor([1, 4, 0, 3, 2])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.argsort(x) for x in norms.unbind(dim=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_protocol(batch, n_entities):\n",
    "    edge_list, labels = batch\n",
    "    rankings_list = list()\n",
    "    hits_at_10_list = list()\n",
    "    batch_size = edge_list.shape[0]\n",
    "\n",
    "    # combine heads, tails and labels\n",
    "    x = torch.hstack([edge_list, labels.reshape(-1,1)])\n",
    "\n",
    "    # reorder column as (h,l,t)\n",
    "    x = x.index_select(dim=1, index=torch.tensor([0,2,1]))\n",
    "\n",
    "    # repeat all triplets for n_entities times\n",
    "    x = x[:,np.newaxis,:].repeat(1,n_entities,1)\n",
    "\n",
    "    # replace all heads with list of all possible entities\n",
    "    x[:,:,0] = torch.tensor(range(n_entities))[np.newaxis,:].repeat(batch_size,1)\n",
    "\n",
    "    e1 = model.entity_mat.weight[x[:,:,0]]\n",
    "    e2 = model.entity_mat.weight[x[:,:,2]]\n",
    "    l = model.relation_mat.weight[x[:,:,1]]\n",
    "\n",
    "    norms = torch.norm(e1+l-e2, dim=2)\n",
    "\n",
    "    rankings = [torch.argsort(x) for x in norms.unbind(dim=0)]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([5, 3, 9, 1, 6, 8, 2, 7, 4, 0]),\n",
       " tensor([5, 1, 2, 3, 9, 8, 6, 4, 7, 0]),\n",
       " tensor([4, 7, 1, 5, 6, 2, 8, 9, 3, 0]),\n",
       " tensor([3, 9, 5, 2, 4, 7, 1, 8, 6, 0]),\n",
       " tensor([0, 8, 6, 9, 4, 1, 7, 5, 3, 2]),\n",
       " tensor([9, 2, 3, 5, 1, 4, 7, 8, 6, 0]),\n",
       " tensor([4, 9, 7, 8, 5, 1, 6, 0, 2, 3]),\n",
       " tensor([9, 8, 1, 6, 7, 0, 4, 3, 5, 2]),\n",
       " tensor([0, 9, 6, 1, 8, 3, 4, 7, 5, 2]),\n",
       " tensor([7, 4, 3, 2, 9, 6, 8, 5, 1, 0]),\n",
       " tensor([7, 4, 1, 3, 2, 9, 6, 0, 8, 5]),\n",
       " tensor([8, 1, 6, 4, 3, 7, 2, 9, 0, 5]),\n",
       " tensor([3, 9, 5, 2, 4, 1, 8, 7, 6, 0]),\n",
       " tensor([2, 5, 9, 7, 4, 1, 8, 6, 3, 0]),\n",
       " tensor([0, 8, 6, 7, 4, 9, 3, 1, 5, 2]),\n",
       " tensor([5, 9, 3, 2, 1, 7, 8, 4, 6, 0]),\n",
       " tensor([4, 2, 7, 8, 5, 6, 9, 1, 3, 0]),\n",
       " tensor([5, 9, 3, 2, 4, 7, 1, 8, 6, 0]),\n",
       " tensor([8, 9, 6, 1, 4, 0, 7, 3, 5, 2]),\n",
       " tensor([6, 1, 8, 2, 7, 3, 0, 4, 5, 9]),\n",
       " tensor([5, 3, 1, 2, 8, 9, 6, 7, 4, 0]),\n",
       " tensor([9, 1, 4, 5, 3, 6, 8, 7, 0, 2]),\n",
       " tensor([3, 9, 5, 1, 4, 6, 7, 8, 2, 0]),\n",
       " tensor([3, 5, 9, 2, 1, 8, 6, 4, 7, 0]),\n",
       " tensor([3, 9, 4, 5, 7, 2, 1, 8, 6, 0]),\n",
       " tensor([7, 4, 8, 9, 0, 6, 5, 1, 3, 2]),\n",
       " tensor([9, 6, 8, 1, 0, 7, 3, 4, 5, 2]),\n",
       " tensor([3, 9, 5, 2, 1, 4, 8, 7, 6, 0]),\n",
       " tensor([9, 4, 2, 3, 7, 5, 1, 8, 0, 6]),\n",
       " tensor([9, 2, 5, 4, 3, 1, 8, 7, 6, 0]),\n",
       " tensor([7, 1, 4, 5, 9, 0, 6, 8, 3, 2]),\n",
       " tensor([1, 8, 6, 7, 9, 4, 0, 3, 2, 5])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_protocol([edge_list, labels], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
